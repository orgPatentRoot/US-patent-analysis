{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature-extract-TransformerXL.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoheikikuta/US-patent-analysis/blob/master/colab/feature_extract_TransformerXL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEr8NHb0hdJg",
        "colab_type": "text"
      },
      "source": [
        "# Feature extraction from TransformerXL model\n",
        "\n",
        "Based on https://github.com/huggingface/pytorch-transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q5B870Yhg66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWLM2sZFhrWr",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shPrhnMphsav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = \"./\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLyecW9RhtcI",
        "colab_type": "code",
        "outputId": "81c3a09a-8e63-4fc7-c6a1-983244c1e7c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "!gsutil cp gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/grants_for_3000+3000.df.gz {DATA_DIR}\n",
        "!gsutil cp gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/testset_app_3000.df.gz {DATA_DIR}\n",
        "!gsutil cp gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/training_app_3000.df.gz {DATA_DIR}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/grants_for_3000+3000.df.gz...\n",
            "/ [1 files][129.4 MiB/129.4 MiB]                                                \n",
            "Operation completed over 1 objects/129.4 MiB.                                    \n",
            "Copying gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/testset_app_3000.df.gz...\n",
            "\\ [1 files][ 45.5 MiB/ 45.5 MiB]                                                \n",
            "Operation completed over 1 objects/45.5 MiB.                                     \n",
            "Copying gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/training_app_3000.df.gz...\n",
            "| [1 files][ 45.0 MiB/ 45.0 MiB]                                                \n",
            "Operation completed over 1 objects/45.0 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8U9GBfbhte1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gzip\n",
        "import pickle\n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gos7_-amhtlq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grants = pd.read_pickle(f\"{DATA_DIR}grants_for_3000+3000.df.gz\")\n",
        "test_app = pd.read_pickle(f\"{DATA_DIR}testset_app_3000.df.gz\")\n",
        "train_app = pd.read_pickle(f\"{DATA_DIR}training_app_3000.df.gz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl9KtfRNhtkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "\n",
        "CLAIM_PAT = re.compile(r'<claims[^>]*>(.*)</claims>',re.MULTILINE|re.DOTALL)\n",
        "TAG_PAT = re.compile(r\"<.*?>\")\n",
        "LB_PAT = re.compile(r'[\\t\\n\\r\\f\\v][\" \"]*')\n",
        "CANCELED_PAT = re.compile(r'[0-9]+.*\\. \\(canceled\\)[\" \"]')\n",
        "NUM_PAT = re.compile(r'[\" \"]?[0-9]+[\" \"]?\\.[\" \"]?')\n",
        "\n",
        "\n",
        "def whole_xml_to_claim_xml(whole):\n",
        "    mat = CLAIM_PAT.search(whole)\n",
        "    return mat.group(1)\n",
        "\n",
        "\n",
        "def whole_xml_to_claim(whole):\n",
        "    return TAG_PAT.sub(' ', whole_xml_to_claim_xml(whole))\n",
        "\n",
        "\n",
        "def remove_linebreak_from_claim(claim):\n",
        "    return LB_PAT.sub('', claim)\n",
        "\n",
        "\n",
        "def remove_canceled_claim(claim):\n",
        "    return CANCELED_PAT.sub('', claim)\n",
        "\n",
        "\n",
        "def remove_claim_numbers(claim):\n",
        "    return NUM_PAT.sub('', claim)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E9MsjTjhti6",
        "colab_type": "code",
        "outputId": "1e57aa9f-211e-43ea-8c67-7c1ade72de00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "train_app[\"claim_app\"] = train_app[\"xml\"].map(whole_xml_to_claim).map(remove_canceled_claim).map(remove_claim_numbers).map(remove_linebreak_from_claim)\n",
        "train_app = train_app.drop(\"xml\", axis=1)\n",
        "\n",
        "test_app[\"claim_app\"] = test_app[\"xml\"].map(whole_xml_to_claim).map(remove_canceled_claim).map(remove_claim_numbers).map(remove_linebreak_from_claim)\n",
        "test_app = test_app.drop(\"xml\", axis=1)\n",
        "\n",
        "grants[\"claim_cited_grant\"] = grants[\"xml\"].map(whole_xml_to_claim).map(remove_canceled_claim).map(remove_claim_numbers).map(remove_linebreak_from_claim)\n",
        "grants = grants.drop(\"xml\", axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8.73 s, sys: 148 ms, total: 8.87 s\n",
            "Wall time: 8.88 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aNh5nHTh2pY",
        "colab_type": "code",
        "outputId": "9cc762e5-caaa-4053-be48-e865dada8e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "train_app.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>app_id</th>\n",
              "      <th>claim_app</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12130785</td>\n",
              "      <td>A system for differentiating noise from an arr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12652424</td>\n",
              "      <td>A method of allocating resources in a data war...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12214532</td>\n",
              "      <td>A controlling method of a media processing app...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     app_id                                          claim_app\n",
              "0  12130785  A system for differentiating noise from an arr...\n",
              "1  12652424  A method of allocating resources in a data war...\n",
              "2  12214532  A controlling method of a media processing app..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gan95fch796",
        "colab_type": "text"
      },
      "source": [
        "## Feature extraction: TransformerXL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWUFJ_Pbc9D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --quiet pytorch-transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIWYf63Xc-Wr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from pytorch_transformers import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvZEk4QodV5V",
        "colab_type": "code",
        "outputId": "f79571d2-4f9d-46a7-aa73-1b79c76c92b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFxoLkaYm0JK",
        "colab_type": "code",
        "outputId": "747ac760-27f0-4b9d-82e8-2bcadf9cb9ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check cuda device is available.\n",
        "torch.cuda.device_count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3lMsKDQdbGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODELS = [(TransfoXLModel,  TransfoXLTokenizer, 'transfo-xl-wt103')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS0kXKoOdmiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's encode some text in a sequence of hidden-states using each model:\n",
        "for model_class, tokenizer_class, pretrained_weights in MODELS:\n",
        "    # Load pretrained model/tokenizer\n",
        "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "    model = model_class.from_pretrained(pretrained_weights,\n",
        "                                      output_hidden_states=False,\n",
        "                                      output_attentions=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OPtHAGLlu8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set cuda device to the model.\n",
        "device = torch.device('cuda:0')\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0dHlEbhpRoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gf-ZCBYqaQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GS_BASE = \"gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-extracted-feature/TransformerXL\"\n",
        "\n",
        "def dump_and_send(fname, obj):\n",
        "  with gzip.open(fname, 'w') as f:\n",
        "     pickle.dump(obj, f)\n",
        "  !gsutil cp {fname} {GS_BASE}/{fname}\n",
        "  print(f\"send to {GS_BASE}/{fname}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ztm5POfQvii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_STR_LEN = 20000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8ncsIcSLgdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_predict(claim):\n",
        "    with torch.no_grad():\n",
        "        input_ids = torch.tensor([tokenizer.encode(claim)]).to(device)\n",
        "        last_hidden_states = model(input_ids)[0]\n",
        "    return np.mean(last_hidden_states.to('cpu').numpy().squeeze(), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrwjbOfbJIVT",
        "colab_type": "code",
        "outputId": "f0faaab5-0804-4e20-b34f-52c526ba53f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "train_features = np.empty((len(train_app), 1024))\n",
        "\n",
        "for idx, claim in enumerate(train_app['claim_app']):\n",
        "    train_features[idx] = model_predict(claim[:MAX_STR_LEN])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 20min 14s, sys: 15min 28s, total: 35min 43s\n",
            "Wall time: 35min 46s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "illAWXWIgJ5M",
        "colab_type": "code",
        "outputId": "ffd63e71-66e6-4123-c96d-3d66cf3d764a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_features.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk8vpmz6gJ_q",
        "colab_type": "code",
        "outputId": "445e851e-3777-4010-84ff-1e39ca473b41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_features[0][:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.25386164,  0.01783523,  0.01317462, -0.08112203, -0.08672263])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scy0nn4hqS0s",
        "colab_type": "code",
        "outputId": "a2b6440d-05e7-43bd-c144-f82ae2af90a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "dump_and_send(\"TransformerXL_feature_train_app_3000.pkl.gz\", train_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://TransformerXL_feature_train_app_3000.pkl.gz [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/12.5 MiB.                                     \n",
            "send to gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-extracted-feature/TransformerXL/TransformerXL_feature_train_app_3000.pkl.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3xZ1Lv5qS7s",
        "colab_type": "code",
        "outputId": "9cf1631b-1138-44c9-951d-655077249aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "test_features = np.empty((len(test_app), 1024))\n",
        "\n",
        "for idx, claim in enumerate(test_app['claim_app']):\n",
        "    test_features[idx] = model_predict(claim[:MAX_STR_LEN])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 20min 35s, sys: 15min 52s, total: 36min 27s\n",
            "Wall time: 36min 30s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqmwM7fnqS6Q",
        "colab_type": "code",
        "outputId": "3f350249-e62e-47fd-d4a4-568f9785ff01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "dump_and_send(\"TransformerXL_feature_test_app_3000.pkl.gz\", test_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://TransformerXL_feature_test_app_3000.pkl.gz [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/12.5 MiB.                                     \n",
            "send to gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-extracted-feature/TransformerXL/TransformerXL_feature_test_app_3000.pkl.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHXrn4EvaLgL",
        "colab_type": "code",
        "outputId": "aa1d77cc-5402-4c44-b301-a1c3fc0a0357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "grants_features = np.empty((len(grants), 1024))\n",
        "\n",
        "for idx, claim in enumerate(grants['claim_cited_grant']):\n",
        "    grants_features[idx] = model_predict(claim[:MAX_STR_LEN])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1h 1min 8s, sys: 47min 59s, total: 1h 49min 7s\n",
            "Wall time: 1h 49min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvtoNkZpaLlH",
        "colab_type": "code",
        "outputId": "c068c8a9-f996-401e-d1df-54c7bdffa603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "dump_and_send(\"TransformerXL_feature_grants_app_3000.pkl.gz\", grants_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://TransformerXL_feature_grants_app_3000.pkl.gz [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/26.8 MiB.                                     \n",
            "send to gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-extracted-feature/TransformerXL/TransformerXL_feature_grants_app_3000.pkl.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvsCeUaNaLsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20dliUrhaLyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq7-02iCqS39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHP3G5d3ctgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjwfZBlcctdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRXv78v2gKX6",
        "colab_type": "text"
      },
      "source": [
        "# Trial and Errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHExhidod_M2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor([tokenizer.encode(\"Let's see all hidden-states and attentions on this text\")])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhsmBbeqemB9",
        "colab_type": "code",
        "outputId": "83e9aab7-25fe-4cd7-da2f-27aea1d0e35e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(input_ids)\n",
        "print(input_ids.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[   24,   611,    73,    24,     5, 34559,    15,    56,  2043]])\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpqIMlySfHSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_output = model(input_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6VQI5f7fKvr",
        "colab_type": "code",
        "outputId": "142cde38-a08e-41ac-9b4f-6d42a8c8aedd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(model_output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYnOMnlffONH",
        "colab_type": "code",
        "outputId": "c31753d4-cc33-4a78-8551-8685ff74d9a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_output[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 9, 1024])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgtd1PveeYL3",
        "colab_type": "code",
        "outputId": "60337c78-8cf0-42a8-d5be-d1f10b4c25e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(len(model_output[1]))\n",
        "print(model_output[1][0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18\n",
            "torch.Size([1600, 1, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SNL8BzWealI",
        "colab_type": "code",
        "outputId": "d51e1ab9-48f6-4a02-f22a-7bdba5e3d4ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(len(model_output[2]))\n",
        "print(model_output[2][0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n",
            "torch.Size([1, 9, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m2qxaUKfkpy",
        "colab_type": "code",
        "outputId": "0198b574-c34a-49ce-8dcd-318766cc9769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "model_output[0] == model_output[2][-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1]]], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huwV2LN0gCBV",
        "colab_type": "code",
        "outputId": "d676ff96-e11d-4357-b789-1a7e277640ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "# Encode text\n",
        "input_ids = torch.tensor([tokenizer.encode(\"Here is some text to encode\"), tokenizer.encode(\"here is some text to encode but in the lower case\"),])\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids)[0]  # Models outputs are now tuples"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-abefd8e4ca0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Here is some text to encode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"here is some text to encode but in the lower case\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlast_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Models outputs are now tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: expected sequence of length 6 at dim 1 (got 11)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdM2dDAqpo8i",
        "colab_type": "text"
      },
      "source": [
        "10 apps (CPU): 6 min 7s  \n",
        "10 apps (GPU): 6 sec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQnfEgbLhNVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Encode text\n",
        "# with torch.no_grad():\n",
        "#     input_ids = torch.tensor([tokenizer.encode(\"Here is some text to encode\")]).to(device)\n",
        "#     print(input_ids)\n",
        "#     last_hidden_states = model(input_ids)[0]  # Models outputs are now tuples\n",
        "# test = last_hidden_states.to('cpu')\n",
        "# del input_ids, last_hidden_states\n",
        "# torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtGVC5jFjAqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}