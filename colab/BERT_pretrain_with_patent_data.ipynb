{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-pretrain-with-patent-data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoheikikuta/US-patent-analysis/blob/master/colab/BERT_pretrain_with_patent_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEkA6FkiZH9S",
        "colab_type": "text"
      },
      "source": [
        "# BERT pretraining with patent data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MZiSo7jZBbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-mBWFwOZaGW",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpJxDRFBZMtx",
        "colab_type": "code",
        "outputId": "6f53b7b4-a1e3-4c77-e8fc-8fd6006a8f21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "!gsutil cp gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-info/citations_info_3000+3000.df.gz ./\n",
        "\n",
        "!gsutil cp gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/training_app_3000.df.gz ./  \n",
        "!gsutil cp gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/testset_app_3000.df.gz ./\n",
        "!gsutil cp gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/grants_for_3000+3000.df.gz ./"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-info/citations_info_3000+3000.df.gz...\n",
            "- [1 files][506.5 KiB/506.5 KiB]                                                \n",
            "Operation completed over 1 objects/506.5 KiB.                                    \n",
            "Copying gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/training_app_3000.df.gz...\n",
            "\\ [1 files][ 45.0 MiB/ 45.0 MiB]                                                \n",
            "Operation completed over 1 objects/45.0 MiB.                                     \n",
            "Copying gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/testset_app_3000.df.gz...\n",
            "/ [1 files][ 45.5 MiB/ 45.5 MiB]                                                \n",
            "Operation completed over 1 objects/45.5 MiB.                                     \n",
            "Copying gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/grants_for_3000+3000.df.gz...\n",
            "/ [1 files][129.4 MiB/129.4 MiB]                                                \n",
            "Operation completed over 1 objects/129.4 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghojum1vZhd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LANBzI0ZsCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "citations_info_target = pd.read_pickle(\"./citations_info_3000+3000.df.gz\")\n",
        "test_app = pd.read_pickle(\"./testset_app_3000.df.gz\")\n",
        "grants = pd.read_pickle(\"./grants_for_3000+3000.df.gz\")\n",
        "train_app = pd.read_pickle(\"./training_app_3000.df.gz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApvBSSuIZt4f",
        "colab_type": "code",
        "outputId": "8e1f3322-66a8-4792-f476-c198e587acdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "source": [
        "train_app.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>app_id</th>\n",
              "      <th>xml</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12130785</td>\n",
              "      <td>&lt;us-patent-application lang=\"EN\" dtd-version=\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12652424</td>\n",
              "      <td>&lt;us-patent-application lang=\"EN\" dtd-version=\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12214532</td>\n",
              "      <td>&lt;us-patent-application lang=\"EN\" dtd-version=\"...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     app_id                                                xml\n",
              "0  12130785  <us-patent-application lang=\"EN\" dtd-version=\"...\n",
              "1  12652424  <us-patent-application lang=\"EN\" dtd-version=\"...\n",
              "2  12214532  <us-patent-application lang=\"EN\" dtd-version=\"..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MgfIJcjZ5Qh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "\n",
        "CLAIM_PAT = re.compile(r'<claims[^>]*>(.*)</claims>',re.MULTILINE|re.DOTALL)\n",
        "TAG_PAT = re.compile(r\"<.*?>\")\n",
        "LB_PAT = re.compile(r'[\\t\\n\\r\\f\\v][\" \"]*')\n",
        "CANCELED_PAT = re.compile(r'[0-9]+.*\\. \\(canceled\\)[\" \"]')\n",
        "NUM_PAT = re.compile(r'[\" \"]?[0-9]+[\" \"]?\\.[\" \"]?')\n",
        "\n",
        "\n",
        "def whole_xml_to_claim_xml(whole):\n",
        "    mat = CLAIM_PAT.search(whole)\n",
        "    return mat.group(1)\n",
        "\n",
        "\n",
        "def whole_xml_to_claim(whole):\n",
        "    return TAG_PAT.sub(' ', whole_xml_to_claim_xml(whole))\n",
        "\n",
        "\n",
        "def remove_linebreak_from_claim(claim):\n",
        "    return LB_PAT.sub('', claim)\n",
        "\n",
        "\n",
        "def remove_canceled_claim(claim):\n",
        "    return CANCELED_PAT.sub('', claim)\n",
        "\n",
        "\n",
        "def remove_claim_numbers(claim):\n",
        "    return NUM_PAT.sub('', claim)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxZ2bK80ag_9",
        "colab_type": "text"
      },
      "source": [
        "Test data will NOT be used for pretraining."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibWuOQAFaYly",
        "colab_type": "code",
        "outputId": "dd0ff53c-e919-450a-a95b-33b8ffd9c333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "train_app[\"claim_app\"] = train_app[\"xml\"].map(whole_xml_to_claim).map(remove_canceled_claim).map(remove_claim_numbers).map(remove_linebreak_from_claim)\n",
        "train_app = train_app.drop(\"xml\", axis=1)\n",
        "train_app.head()\n",
        "\n",
        "# test_app[\"claim_app\"] = test_app[\"xml\"].map(whole_xml_to_claim).map(remove_canceled_claim).map(remove_claim_numbers).map(remove_linebreak_from_claim)\n",
        "# test_app = test_app.drop(\"xml\", axis=1)\n",
        "# test_app.head()\n",
        "\n",
        "grants[\"claim_cited_grant\"] = grants[\"xml\"].map(whole_xml_to_claim).map(remove_canceled_claim).map(remove_claim_numbers).map(remove_linebreak_from_claim)\n",
        "grants = grants.drop(\"xml\", axis=1)\n",
        "grants.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.66 s, sys: 188 ms, total: 7.84 s\n",
            "Wall time: 7.85 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8oloFzVavKv",
        "colab_type": "code",
        "outputId": "2d4956e0-9ccd-43e8-8d19-4b78d671feaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "source": [
        "train_app.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>app_id</th>\n",
              "      <th>claim_app</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12130785</td>\n",
              "      <td>A system for differentiating noise from an arr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12652424</td>\n",
              "      <td>A method of allocating resources in a data war...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12214532</td>\n",
              "      <td>A controlling method of a media processing app...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     app_id                                          claim_app\n",
              "0  12130785  A system for differentiating noise from an arr...\n",
              "1  12652424  A method of allocating resources in a data war...\n",
              "2  12214532  A controlling method of a media processing app..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEXJyiViav65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = train_app['claim_app'][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwoWe3jta1pX",
        "colab_type": "code",
        "outputId": "cffec5da-42d5-4220-9527-2e9d8cdb6ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "test.replace(\".\", \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A system for differentiating noise from an arrhythmia of a heart, comprising:a noise discriminator configured to receive an electrocardiogram (EGM) signal and to discriminate between an organized EGM signal and a chaotic EGM signal based at least in part on an impedance parameter associated with a lead that provides an electrical connection to the heart; a signal analyzer configured to determine whether a chaotic signal is caused by a disturbance in the lead\\n The system of  claim 1 , further comprising a high voltage delivery system configured to deliver a high voltage therapy signal to the heart if the EGM signal is an organized signal\\n The system of  claim 2 , further comprising a high voltage confirmation system configured to adjust or terminate the high voltage therapy based on the impedance parameter\\n The system of  claim 3 , wherein the signal analyzer is part of the high voltage confirmation system\\n The system of  claim 3 , wherein the lead comprises a high voltage lead for delivering the high voltage signal to the heart\\n The system of  claim 3 , wherein the impedance parameter comprises an impedance value associated with an electrical connection of the lead with the heart\\n The system of  claim 3 , wherein the impedance parameter comprises an integrated value of impedance associated with an electrical connection of the lead with the heart\\n The system of  claim 1 , wherein the signal analyzer determines whether the chaotic signal is caused by lead disturbance by comparing the impedance parameter with a known threshold value\\n The system of  claim 8 , wherein the known threshold value comprises a threshold impedance value for the lead corresponding to a failure condition of the lead\\n The system of  claim 9 , wherein the failure condition of the lead and the corresponding threshold impedance value are determined by providing a simulated operating condition of the lead in a laboratory\\n An implantable cardiac device, comprising:a high voltage device configured to deliver a therapy signal to a heart when triggered; an electrical lead for connecting the high voltage device to the heart; an impedance measurement component configured to measure an electrical impedance associated with the electrical lead; and a processor configured to provide a command for operation of the high voltage device based at least in part on a parameter associated with the measured electrical impedance\\n The system of  claim 11 , wherein the parameter comprises an electrical resistance\\n The system of  claim 11 , wherein the parameter comprises an integrated value of electrical resistance over a period of time\\n The system of  claim 11 , wherein the processor provides the command based on comparison of the parameter with a known reference value\\n The system of  claim 14 , wherein the known reference value is stored in the implantable cardiac device, and obtained from a laboratory study that simulates degradation of the electrical lead\\n The system of  claim 15 , wherein the known reference value is obtained by correlating an observed failure condition with a corresponding value of the parameter\\n The system of  claim 11 , wherein the command comprises a termination command that terminates a process for delivering the therapy signal\\n The system of  claim 11 , wherein the command comprises an adjustment command that adjusts the therapy signal\\n A method for operating an implantable cardiac device, comprising:measuring an impedance value associated with at least one of a plurality of electrical leads for a high voltage device configured to provide a therapy signal, wherein the plurality of electrical leads are configured to be connected to a heart and deliver the therapy signal to the heart; and generating a command for operation of the high voltage device based at least in part on the measured impedance value\\n A method for differentiating noise from an arrhythmia of a heart, comprising:receiving an electrocardiogram (EGM) signal; measuring an impedance parameter associated with a lead that provides an electrical connection to the heart; and determining whether the EGM signal is an organized signal or a chaotic signal based at least in part on the measured impedance parameter\\n  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2GCTLbkdCTu",
        "colab_type": "text"
      },
      "source": [
        "In order to make a pretraining data, use simple preprocessing: replacing a (period + space) with (period + line break)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4O4uR5Hbb-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open(\"./test.txt\", \"w+\") as f:\n",
        "#     f.write(test.replace(\". \", \".\\n\").lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWOHlwl1cMom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cat ./test.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NKg0gcucbr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(pd.concat([train_app['claim_app'], grants['claim_cited_grant']]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6WF30ogdy1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%time\n",
        "\n",
        "# with open(\"./training_data.txt\", \"w+\") as f:\n",
        "#     for one_stuff in pd.concat([train_app['claim_app'], grants['claim_cited_grant']]):\n",
        "#         f.write(one_stuff.replace(\". \", \".\\n\").lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv1dGyvrev7R",
        "colab_type": "text"
      },
      "source": [
        "## Create training data for BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67mlvTtp0YLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Patent 2017 text data.\n",
        "# !gsutil cp gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/training_data.txt ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUB0geNBYhmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wc -l ./training_data.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzI3IEg1amac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !sed -n 510000,510010p ./training_data.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DvnxbT6a0W5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !sed -n 1020000,1020010p ./training_data.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr--6KbQbSt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !sed -n 1,510004p ./training_data.txt > ./training_data_1.txt\n",
        "# !sed -n 510005,1020003p ./training_data.txt > ./training_data_2.txt\n",
        "# !sed -n 1020004,1528943p ./training_data.txt > ./training_data_3.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKBYvybOeeM0",
        "colab_type": "code",
        "outputId": "7f598d32-714e-4eca-94e7-7a069d6df475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "!git clone https://github.com/google-research/bert.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 333, done.\u001b[K\n",
            "remote: Total 333 (delta 0), reused 0 (delta 0), pack-reused 333\u001b[K\n",
            "Receiving objects: 100% (333/333), 279.30 KiB | 3.83 MiB/s, done.\n",
            "Resolving deltas: 100% (183/183), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a96WSrtefUKb",
        "colab_type": "code",
        "outputId": "6a6581f0-2d9b-463a-d851-8211816d09a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "!gsutil cp -r gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12 ./"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/bert_config.json...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/bert_model.ckpt.index...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/bert_model.ckpt.meta...\n",
            "\\ [4 files][420.9 MiB/420.9 MiB]                                                \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/checkpoint...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/vocab.txt...\n",
            "/ [6 files][421.1 MiB/421.1 MiB]   15.7 MiB/s                                   \n",
            "Operation completed over 6 objects/421.1 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SbZCuTAfg23",
        "colab_type": "code",
        "outputId": "cdf129d1-190f-4aee-fd29-b9abcdfdb3cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json\t\t\tsample_data\n",
            "bert\t\t\t\ttestset_app_3000.df.gz\n",
            "citations_info_3000+3000.df.gz\ttraining_app_3000.df.gz\n",
            "grants_for_3000+3000.df.gz\tuncased_L-12_H-768_A-12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m9L8nSlfsWz",
        "colab_type": "code",
        "outputId": "cb3821ed-a1b5-4415-f01b-8707acc31e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%cd bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/bert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jm9alRxgObM",
        "colab_type": "code",
        "outputId": "79acbdad-9e74-42af-b1bc-f6c3a848fa34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONTRIBUTING.md\t\t    predicting_movie_reviews_with_bert_on_tf_hub.ipynb\n",
            "create_pretraining_data.py  README.md\n",
            "extract_features.py\t    requirements.txt\n",
            "__init__.py\t\t    run_classifier.py\n",
            "LICENSE\t\t\t    run_classifier_with_tfhub.py\n",
            "modeling.py\t\t    run_pretraining.py\n",
            "modeling_test.py\t    run_squad.py\n",
            "multilingual.md\t\t    sample_text.txt\n",
            "optimization.py\t\t    tokenization.py\n",
            "optimization_test.py\t    tokenization_test.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-j1rUNugPQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%time\n",
        "\n",
        "# !python create_pretraining_data.py \\\n",
        "#   --input_file=../training_data_3.txt \\\n",
        "#   --output_file=../training_data_3.tfrecord \\\n",
        "#   --vocab_file=../uncased_L-12_H-768_A-12/vocab.txt \\\n",
        "#   --do_lower_case=True \\\n",
        "#   --max_seq_length=512 \\\n",
        "#   --max_predictions_per_seq=20 \\\n",
        "#   --masked_lm_prob=0.15 \\\n",
        "#   --random_seed=12345 \\\n",
        "#   --dupe_factor=5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpFcIvb4ghzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# About 350 [MiB]\n",
        "\n",
        "# !stat -c %s ../training_data.tfrecord"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSmrMZ5_qNy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !gsutil cp ../training_data.tfrecord gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-pretrain-BERT/\n",
        "# !gsutil cp ../training_data_1.tfrecord gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/\n",
        "# !gsutil cp ../training_data_2.tfrecord gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/\n",
        "# !gsutil cp ../training_data_3.tfrecord gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LntB4_akkNrb",
        "colab_type": "text"
      },
      "source": [
        "## Pretraining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77gFndWpk-vR",
        "colab_type": "code",
        "outputId": "3b1f1ec1-ea39-41db-a39e-81df75e30834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.103.140.138:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 4676900968595902608),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 9114757423999702320),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7352254183043986764),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 17823823701263564679),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 4511093959183907878),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8119742463973857164),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 7218021206714621563),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 18249821039556106535),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 14641978516983987952),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 15069812632313013132),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 14349473264704548868)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTnTutlBv9Zu",
        "colab_type": "text"
      },
      "source": [
        "NOTE: need to give access rights to INIT_CKPT GCS to cloud TPUs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3Kq1GhgoAlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# INPUT_FILE = \"gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-pretrain-BERT/training_data.tfrecord\"\n",
        "# OUTPUT_GCS = \"gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-pretrain-BERT\"\n",
        "# INIT_CKPT = \"gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/bert_model.ckpt\"\n",
        "\n",
        "INPUT_FILE = \"gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT\"\n",
        "OUTPUT_GCS = \"gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT\"\n",
        "INIT_CKPT = \"gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/bert_model.ckpt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQCDqxFgj5gq",
        "colab_type": "code",
        "outputId": "8146c54f-1884-4032-da16-9f6c9c7a0149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "!python run_pretraining.py \\\n",
        "  --input_file={INPUT_FILE}/training_data_1.tfrecord,{INPUT_FILE}/training_data_2.tfrecord,{INPUT_FILE}/training_data_3.tfrecord \\\n",
        "  --output_dir={OUTPUT_GCS} \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name={TPU_ADDRESS} \\\n",
        "  --num_tpu_cores=8 \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=True \\\n",
        "  --bert_config_file=../uncased_L-12_H-768_A-12/bert_config.json \\\n",
        "  --train_batch_size=64 \\\n",
        "  --max_seq_length=512 \\\n",
        "  --max_predictions_per_seq=20 \\\n",
        "  --num_train_steps=300000 \\\n",
        "  --num_warmup_steps=1000 \\\n",
        "  --learning_rate=5e-5\n",
        "#   --init_checkpoint={INIT_CKPT}  # Only need to add at the first training time."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0820 05:35:43.306933 139671258257280 deprecation_wrapper.py:119] From /content/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0820 05:35:43.308188 139671258257280 deprecation_wrapper.py:119] From run_pretraining.py:493: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0820 05:35:43.308779 139671258257280 deprecation_wrapper.py:119] From run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0820 05:35:43.308923 139671258257280 deprecation_wrapper.py:119] From run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0820 05:35:43.309074 139671258257280 deprecation_wrapper.py:119] From /content/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0820 05:35:43.309868 139671258257280 deprecation_wrapper.py:119] From run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0820 05:35:44.723505 139671258257280 deprecation_wrapper.py:119] From run_pretraining.py:418: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0820 05:35:45.429849 139671258257280 deprecation_wrapper.py:119] From run_pretraining.py:420: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0820 05:35:45.430114 139671258257280 run_pretraining.py:420] *** Input Files ***\n",
            "I0820 05:35:45.430206 139671258257280 run_pretraining.py:422]   gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/training_data_1.tfrecord\n",
            "I0820 05:35:45.430288 139671258257280 run_pretraining.py:422]   gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/training_data_2.tfrecord\n",
            "I0820 05:35:45.430361 139671258257280 run_pretraining.py:422]   gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/training_data_3.tfrecord\n",
            "W0820 05:35:46.378371 139671258257280 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0820 05:35:47.383703 139671258257280 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f0789c221e0>) includes params argument, but params are not passed to Estimator.\n",
            "I0820 05:35:47.385270 139671258257280 estimator.py:209] Using config: {'_model_dir': 'gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.103.140.138:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0789bbf470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.103.140.138:8470', '_evaluation_master': 'grpc://10.103.140.138:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f0795e69dd8>}\n",
            "I0820 05:35:47.385591 139671258257280 tpu_context.py:209] _TPUContext: eval_on_tpu True\n",
            "I0820 05:35:47.386271 139671258257280 run_pretraining.py:459] ***** Running training *****\n",
            "I0820 05:35:47.386362 139671258257280 run_pretraining.py:460]   Batch size = 64\n",
            "I0820 05:35:53.956954 139671258257280 tpu_system_metadata.py:78] Querying Tensorflow master (grpc://10.103.140.138:8470) for TPU system metadata.\n",
            "2019-08-20 05:35:53.958291: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:356] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "I0820 05:35:53.971397 139671258257280 tpu_system_metadata.py:148] Found TPU system:\n",
            "I0820 05:35:53.971607 139671258257280 tpu_system_metadata.py:149] *** Num TPU Cores: 8\n",
            "I0820 05:35:53.971698 139671258257280 tpu_system_metadata.py:150] *** Num TPU Workers: 1\n",
            "I0820 05:35:53.971766 139671258257280 tpu_system_metadata.py:152] *** Num TPU Cores Per Worker: 8\n",
            "I0820 05:35:53.971832 139671258257280 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 4676900968595902608)\n",
            "I0820 05:35:53.972674 139671258257280 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7352254183043986764)\n",
            "I0820 05:35:53.972762 139671258257280 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 17823823701263564679)\n",
            "I0820 05:35:53.972836 139671258257280 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 4511093959183907878)\n",
            "I0820 05:35:53.972902 139671258257280 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8119742463973857164)\n",
            "I0820 05:35:53.972983 139671258257280 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 7218021206714621563)\n",
            "I0820 05:35:53.973052 139671258257280 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 18249821039556106535)\n",
            "I0820 05:35:53.973115 139671258257280 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 14641978516983987952)\n",
            "I0820 05:35:53.973191 139671258257280 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 15069812632313013132)\n",
            "I0820 05:35:53.973253 139671258257280 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 14349473264704548868)\n",
            "I0820 05:35:53.973328 139671258257280 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 9114757423999702320)\n",
            "W0820 05:35:53.979591 139671258257280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "I0820 05:35:53.996150 139671258257280 estimator.py:1145] Calling model_fn.\n",
            "W0820 05:35:53.996811 139671258257280 deprecation_wrapper.py:119] From run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0820 05:35:54.002897 139671258257280 deprecation.py:323] From run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0820 05:35:54.003076 139671258257280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0820 05:35:54.029049 139671258257280 deprecation.py:323] From run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0820 05:35:54.029268 139671258257280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0820 05:35:54.030718 139671258257280 deprecation_wrapper.py:119] From run_pretraining.py:393: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0820 05:35:54.036579 139671258257280 deprecation.py:323] From run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "I0820 05:35:54.116104 139671258257280 run_pretraining.py:117] *** Features ***\n",
            "I0820 05:35:54.116351 139671258257280 run_pretraining.py:119]   name = input_ids, shape = (8, 512)\n",
            "I0820 05:35:54.116456 139671258257280 run_pretraining.py:119]   name = input_mask, shape = (8, 512)\n",
            "I0820 05:35:54.116543 139671258257280 run_pretraining.py:119]   name = masked_lm_ids, shape = (8, 20)\n",
            "I0820 05:35:54.116633 139671258257280 run_pretraining.py:119]   name = masked_lm_positions, shape = (8, 20)\n",
            "I0820 05:35:54.116716 139671258257280 run_pretraining.py:119]   name = masked_lm_weights, shape = (8, 20)\n",
            "I0820 05:35:54.116796 139671258257280 run_pretraining.py:119]   name = next_sentence_labels, shape = (8, 1)\n",
            "I0820 05:35:54.116873 139671258257280 run_pretraining.py:119]   name = segment_ids, shape = (8, 512)\n",
            "W0820 05:35:54.117099 139671258257280 deprecation_wrapper.py:119] From /content/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0820 05:35:54.119118 139671258257280 deprecation_wrapper.py:119] From /content/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0820 05:35:54.152916 139671258257280 deprecation_wrapper.py:119] From /content/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0820 05:35:54.319336 139671258257280 deprecation.py:506] From /content/bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0820 05:35:54.339817 139671258257280 deprecation.py:323] From /content/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "I0820 05:35:58.103025 139671258257280 run_pretraining.py:167] **** Trainable Variables ****\n",
            "I0820 05:35:58.103251 139671258257280 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (30522, 768)\n",
            "I0820 05:35:58.103370 139671258257280 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "I0820 05:35:58.103461 139671258257280 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "I0820 05:35:58.103549 139671258257280 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.103633 139671258257280 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.103714 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.103796 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 05:35:58.103874 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.103952 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 05:35:58.104046 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.104125 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 05:35:58.104199 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.104285 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.104359 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.104432 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.104505 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 05:35:58.104582 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 05:35:58.104657 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 05:35:58.104733 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.104808 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.104881 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.104954 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.105046 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 05:35:58.105121 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.105197 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 05:35:58.105277 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.105354 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 05:35:58.105427 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.105505 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.105585 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.105660 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.105733 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 05:35:58.105811 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 05:35:58.105885 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 05:35:58.105965 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.106054 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.106128 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.106201 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.106284 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 05:35:58.106359 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.106436 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 05:35:58.106509 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.106584 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 05:35:58.106659 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.106734 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.106815 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.106889 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.106962 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 05:35:58.107054 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 05:35:58.107128 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 05:35:58.107204 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.107285 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.107357 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.107430 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.107506 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 05:35:58.107584 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.107662 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 05:35:58.107736 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.107815 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 05:35:58.107888 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.107965 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.108054 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.108128 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.108201 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 05:35:58.108286 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 05:35:58.108361 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 05:35:58.108437 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.108511 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.108584 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.108657 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.108734 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 05:35:58.108810 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.108886 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 05:35:58.108959 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.109051 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 05:35:58.109124 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.109207 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.109287 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.109361 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.109434 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 05:35:58.109511 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 05:35:58.109584 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 05:35:58.109663 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.109736 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.109810 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.109884 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.109961 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 05:35:58.110048 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.110125 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 05:35:58.110199 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.110282 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 05:35:58.110356 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.110433 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.110506 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.110579 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.110652 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 05:35:58.110728 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 05:35:58.110802 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 05:35:58.110879 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.110953 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.111039 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.111112 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.111189 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 05:35:58.111267 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.111345 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 05:35:58.111418 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.111496 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 05:35:58.111570 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.111648 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.111733 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.111808 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.111881 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 05:35:58.111958 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 05:35:58.112047 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 05:35:58.112125 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.112200 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.112279 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.112353 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.112431 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 05:35:58.112504 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.112581 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 05:35:58.112655 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.198863 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 05:35:58.199151 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.199329 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.199469 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.199584 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.199706 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 05:35:58.199824 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 05:35:58.199946 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 05:35:58.200087 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.200193 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.200312 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.200417 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.200546 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 05:35:58.200655 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.200765 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 05:35:58.200867 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.200999 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 05:35:58.201119 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.201240 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.201347 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.201449 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.201567 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 05:35:58.201687 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 05:35:58.201808 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 05:35:58.201923 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.202052 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.202155 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.202269 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.202378 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 05:35:58.202480 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.202588 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 05:35:58.202687 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.202794 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 05:35:58.202894 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.203021 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.203128 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.203227 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.203341 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 05:35:58.203445 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 05:35:58.203547 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 05:35:58.203651 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.203754 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.203855 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.203953 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.204078 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 05:35:58.204172 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.204281 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 05:35:58.204381 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.204482 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 05:35:58.204579 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.204680 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.204777 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.204873 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.204984 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 05:35:58.205096 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 05:35:58.205200 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 05:35:58.205321 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.205423 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.205524 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.205623 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.205728 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 05:35:58.205833 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.205941 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 05:35:58.206066 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.206173 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 05:35:58.206289 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.206398 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.206499 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.206601 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.206701 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 05:35:58.206807 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 05:35:58.206909 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 05:35:58.207042 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.207145 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.207259 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.207366 139671258257280 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.207474 139671258257280 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.207575 139671258257280 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
            "I0820 05:35:58.207682 139671258257280 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
            "I0820 05:35:58.207783 139671258257280 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 05:35:58.207883 139671258257280 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 05:35:58.208002 139671258257280 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (30522,)\n",
            "I0820 05:35:58.208110 139671258257280 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
            "I0820 05:35:58.208214 139671258257280 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
            "W0820 05:35:58.208425 139671258257280 deprecation_wrapper.py:119] From /content/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0820 05:35:58.210108 139671258257280 deprecation_wrapper.py:119] From /content/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0820 05:35:58.217864 139671258257280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0820 05:35:58.543380 139671258257280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "I0820 05:36:12.017034 139671258257280 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0820 05:36:12.646930 139671258257280 estimator.py:1147] Done calling model_fn.\n",
            "I0820 05:36:16.322863 139671258257280 tpu_estimator.py:499] TPU job name worker\n",
            "I0820 05:36:17.698930 139671258257280 monitored_session.py:240] Graph was finalized.\n",
            "W0820 05:36:17.856220 139671258257280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0820 05:36:18.092026 139671258257280 saver.py:1280] Restoring parameters from gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt-232000\n",
            "W0820 05:36:50.764264 139671258257280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "I0820 05:36:53.638780 139671258257280 session_manager.py:500] Running local_init_op.\n",
            "I0820 05:36:54.407366 139671258257280 session_manager.py:502] Done running local_init_op.\n",
            "I0820 05:37:06.441649 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 232000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "W0820 05:37:37.134941 139671258257280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:741: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "I0820 05:37:38.752693 139671258257280 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "I0820 05:37:38.753774 139671258257280 session_support.py:332] Installing graceful shutdown hook.\n",
            "2019-08-20 05:37:38.754183: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:356] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "I0820 05:37:38.759195 139671258257280 session_support.py:82] Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "I0820 05:37:38.761085 139671258257280 session_support.py:105] Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "I0820 05:37:38.765308 139671258257280 tpu_estimator.py:557] Init TPU system\n",
            "I0820 05:37:46.232445 139671258257280 tpu_estimator.py:566] Initialized TPU in 7 seconds\n",
            "I0820 05:37:46.233392 139670110246656 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "I0820 05:37:46.233876 139670084032256 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "I0820 05:37:47.040619 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 05:37:47.041597 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 05:38:17.419159 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "I0820 05:39:17.524247 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (0, 252)\n",
            "I0820 05:40:17.630071 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (0, 504)\n",
            "I0820 05:41:17.735685 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (0, 756)\n",
            "I0820 05:42:16.590653 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 233000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "W0820 05:42:56.367143 139671258257280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "I0820 05:43:03.102878 139671258257280 basic_session_run_hooks.py:262] loss = 0.28346214, step = 233000\n",
            "I0820 05:43:03.105153 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 05:43:03.105350 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 05:43:11.745113 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (1, 0)\n",
            "I0820 05:44:11.846581 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (1, 252)\n",
            "I0820 05:45:11.950603 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (1, 504)\n",
            "I0820 05:46:12.054991 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (1, 756)\n",
            "I0820 05:47:10.880127 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 234000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 05:47:43.459522 139671258257280 basic_session_run_hooks.py:260] loss = 0.24460599, step = 234000 (280.357 sec)\n",
            "I0820 05:47:43.461281 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.56688\n",
            "I0820 05:47:43.462208 139671258257280 tpu_estimator.py:2160] examples/sec: 228.28\n",
            "I0820 05:47:43.463798 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 05:47:43.463990 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 05:47:44.822568 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (2, 0)\n",
            "I0820 05:48:44.920761 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (2, 252)\n",
            "I0820 05:49:45.022419 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (2, 504)\n",
            "I0820 05:50:45.129651 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (2, 756)\n",
            "I0820 05:51:43.932767 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 235000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 05:52:22.963995 139671258257280 basic_session_run_hooks.py:260] loss = 0.20725048, step = 235000 (279.504 sec)\n",
            "I0820 05:52:22.965718 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.57776\n",
            "I0820 05:52:22.966159 139671258257280 tpu_estimator.py:2160] examples/sec: 228.977\n",
            "I0820 05:52:22.967637 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 05:52:22.967811 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 05:52:24.257273 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (3, 0)\n",
            "I0820 05:53:24.357167 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (3, 252)\n",
            "I0820 05:54:24.459076 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (3, 504)\n",
            "I0820 05:55:24.561825 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (3, 756)\n",
            "I0820 05:56:23.367658 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 236000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 05:56:55.130572 139671258257280 basic_session_run_hooks.py:260] loss = 0.30533674, step = 236000 (272.167 sec)\n",
            "I0820 05:56:55.132205 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.67422\n",
            "I0820 05:56:55.132631 139671258257280 tpu_estimator.py:2160] examples/sec: 235.15\n",
            "I0820 05:56:55.133756 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 05:56:55.133953 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 05:56:56.475250 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (4, 0)\n",
            "I0820 05:57:56.578085 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (4, 252)\n",
            "I0820 05:58:56.683267 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (4, 504)\n",
            "I0820 05:59:56.788432 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (4, 756)\n",
            "I0820 06:00:55.628467 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 237000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 06:01:39.210493 139671258257280 basic_session_run_hooks.py:260] loss = 0.32636636, step = 237000 (284.080 sec)\n",
            "I0820 06:01:39.212008 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.52014\n",
            "I0820 06:01:39.212303 139671258257280 tpu_estimator.py:2160] examples/sec: 225.289\n",
            "I0820 06:01:39.213529 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 06:01:39.213692 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 06:01:40.564604 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (5, 0)\n",
            "I0820 06:02:40.667455 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (5, 252)\n",
            "I0820 06:03:40.780200 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (5, 504)\n",
            "I0820 06:04:40.878391 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (5, 756)\n",
            "I0820 06:05:39.727562 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 238000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 06:06:12.934316 139671258257280 basic_session_run_hooks.py:260] loss = 0.21720608, step = 238000 (273.724 sec)\n",
            "I0820 06:06:12.936058 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.65331\n",
            "I0820 06:06:12.936384 139671258257280 tpu_estimator.py:2160] examples/sec: 233.812\n",
            "I0820 06:06:12.937477 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 06:06:12.937672 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 06:06:14.219739 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (6, 0)\n",
            "I0820 06:07:14.317362 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (6, 252)\n",
            "I0820 06:08:14.444409 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (6, 504)\n",
            "I0820 06:09:14.582929 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (6, 756)\n",
            "I0820 06:10:13.427358 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 239000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 06:10:48.006784 139671258257280 basic_session_run_hooks.py:260] loss = 0.10788077, step = 239000 (275.072 sec)\n",
            "I0820 06:10:48.008315 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.63541\n",
            "I0820 06:10:48.008474 139671258257280 tpu_estimator.py:2160] examples/sec: 232.666\n",
            "I0820 06:10:48.009699 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 06:10:48.009863 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 06:10:49.385648 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (7, 0)\n",
            "I0820 06:11:49.511234 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (7, 252)\n",
            "I0820 06:12:49.636254 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (7, 504)\n",
            "I0820 06:13:49.758826 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (7, 756)\n",
            "I0820 06:14:48.593064 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 240000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 06:15:27.891100 139671258257280 basic_session_run_hooks.py:260] loss = 0.3704614, step = 240000 (279.884 sec)\n",
            "I0820 06:15:27.892666 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.5729\n",
            "I0820 06:15:27.892838 139671258257280 tpu_estimator.py:2160] examples/sec: 228.666\n",
            "I0820 06:15:27.894134 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 06:15:27.894337 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 06:15:29.241187 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (8, 0)\n",
            "I0820 06:16:29.352413 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (8, 252)\n",
            "I0820 06:17:29.463937 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (8, 504)\n",
            "I0820 06:18:29.574967 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (8, 756)\n",
            "I0820 06:19:28.420067 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 241000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 06:20:00.182339 139671258257280 basic_session_run_hooks.py:260] loss = 0.34790194, step = 241000 (272.291 sec)\n",
            "I0820 06:20:00.184127 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.67254\n",
            "I0820 06:20:00.184324 139671258257280 tpu_estimator.py:2160] examples/sec: 235.042\n",
            "I0820 06:20:00.185649 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 06:20:00.185863 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 06:20:01.489477 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (9, 0)\n",
            "I0820 06:21:01.600620 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (9, 252)\n",
            "I0820 06:22:01.713356 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (9, 504)\n",
            "I0820 06:23:01.825196 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (9, 756)\n",
            "I0820 06:24:00.660948 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 242000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 06:24:43.393007 139671258257280 basic_session_run_hooks.py:260] loss = 0.2577638, step = 242000 (283.211 sec)\n",
            "I0820 06:24:43.394550 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.53094\n",
            "I0820 06:24:43.394726 139671258257280 tpu_estimator.py:2160] examples/sec: 225.98\n",
            "I0820 06:24:43.396086 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 06:24:43.396256 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 06:24:44.727838 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (10, 0)\n",
            "I0820 06:25:44.838418 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (10, 252)\n",
            "I0820 06:26:44.949331 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (10, 504)\n",
            "I0820 06:27:45.060415 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (10, 756)\n",
            "I0820 06:28:43.898890 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 243000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 06:29:24.672355 139671258257280 basic_session_run_hooks.py:260] loss = 0.6069823, step = 243000 (281.279 sec)\n",
            "I0820 06:29:24.674503 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.55518\n",
            "I0820 06:29:24.674901 139671258257280 tpu_estimator.py:2160] examples/sec: 227.531\n",
            "I0820 06:29:24.676306 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 06:29:24.676486 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 06:29:26.050416 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (11, 0)\n",
            "I0820 06:30:26.158660 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (11, 252)\n",
            "I0820 06:31:26.266799 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (11, 504)\n",
            "I0820 06:32:26.375706 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (11, 756)\n",
            "I0820 06:33:25.235955 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 244000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 06:34:06.034601 139671258257280 basic_session_run_hooks.py:260] loss = 0.13320541, step = 244000 (281.362 sec)\n",
            "I0820 06:34:06.036535 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.55414\n",
            "I0820 06:34:06.037061 139671258257280 tpu_estimator.py:2160] examples/sec: 227.465\n",
            "I0820 06:34:06.038544 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 06:34:06.038734 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 06:34:07.362478 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (12, 0)\n",
            "I0820 06:35:07.471751 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (12, 252)\n",
            "I0820 06:36:07.582803 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (12, 504)\n",
            "I0820 06:37:07.693500 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (12, 756)\n",
            "I0820 06:38:06.516007 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 245000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 06:38:50.652631 139671258257280 basic_session_run_hooks.py:260] loss = 0.46110648, step = 245000 (284.618 sec)\n",
            "I0820 06:38:50.654492 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.51348\n",
            "I0820 06:38:50.654708 139671258257280 tpu_estimator.py:2160] examples/sec: 224.863\n",
            "I0820 06:38:50.656112 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 06:38:50.656344 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 06:38:52.046721 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (13, 0)\n",
            "I0820 06:39:52.155363 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (13, 252)\n",
            "I0820 06:40:52.264398 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (13, 504)\n",
            "I0820 06:41:52.373458 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (13, 756)\n",
            "I0820 06:42:51.166582 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 246000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 06:43:32.379926 139671258257280 basic_session_run_hooks.py:260] loss = 0.35278141, step = 246000 (281.727 sec)\n",
            "I0820 06:43:32.381509 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.54954\n",
            "I0820 06:43:32.381963 139671258257280 tpu_estimator.py:2160] examples/sec: 227.17\n",
            "I0820 06:43:32.383216 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 06:43:32.383405 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 06:43:33.759495 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (14, 0)\n",
            "I0820 06:44:33.866569 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (14, 252)\n",
            "I0820 06:45:33.975607 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (14, 504)\n",
            "I0820 06:46:34.082272 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (14, 756)\n",
            "I0820 06:47:32.866031 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 247000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 06:48:09.826914 139671258257280 basic_session_run_hooks.py:260] loss = 0.525845, step = 247000 (277.447 sec)\n",
            "I0820 06:48:09.828672 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.60429\n",
            "I0820 06:48:09.829000 139671258257280 tpu_estimator.py:2160] examples/sec: 230.675\n",
            "I0820 06:48:09.830366 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 06:48:09.830520 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 06:48:11.135912 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (15, 0)\n",
            "I0820 06:49:11.243648 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (15, 252)\n",
            "I0820 06:50:11.353625 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (15, 504)\n",
            "I0820 06:51:11.463657 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (15, 756)\n",
            "I0820 06:52:10.291013 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 248000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 06:52:45.114061 139671258257280 basic_session_run_hooks.py:260] loss = 0.4291611, step = 248000 (275.287 sec)\n",
            "I0820 06:52:45.115731 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.63257\n",
            "I0820 06:52:45.116129 139671258257280 tpu_estimator.py:2160] examples/sec: 232.485\n",
            "I0820 06:52:45.117516 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 06:52:45.117695 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 06:52:46.484849 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (16, 0)\n",
            "I0820 06:53:46.592118 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (16, 252)\n",
            "I0820 06:54:46.700326 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (16, 504)\n",
            "I0820 06:55:46.808865 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (16, 756)\n",
            "I0820 06:56:45.674378 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 249000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 06:57:21.034954 139671258257280 basic_session_run_hooks.py:260] loss = 0.28456366, step = 249000 (275.921 sec)\n",
            "I0820 06:57:21.036913 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.62422\n",
            "I0820 06:57:21.037467 139671258257280 tpu_estimator.py:2160] examples/sec: 231.95\n",
            "I0820 06:57:21.039170 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 06:57:21.039345 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 06:57:22.377412 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (17, 0)\n",
            "I0820 06:58:22.483659 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (17, 252)\n",
            "I0820 06:59:22.593719 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (17, 504)\n",
            "I0820 07:00:22.702823 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (17, 756)\n",
            "I0820 07:01:21.548590 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 250000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 07:01:56.359734 139671258257280 basic_session_run_hooks.py:260] loss = 0.20777279, step = 250000 (275.325 sec)\n",
            "I0820 07:01:56.361769 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.63207\n",
            "I0820 07:01:56.362378 139671258257280 tpu_estimator.py:2160] examples/sec: 232.453\n",
            "I0820 07:01:56.364406 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 07:01:56.364668 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 07:01:57.694390 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (18, 0)\n",
            "I0820 07:02:57.803057 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (18, 252)\n",
            "I0820 07:03:57.914129 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (18, 504)\n",
            "I0820 07:04:58.025081 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (18, 756)\n",
            "I0820 07:05:56.862960 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 251000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 07:06:39.150934 139671258257280 basic_session_run_hooks.py:260] loss = 0.5351019, step = 251000 (282.791 sec)\n",
            "I0820 07:06:39.152516 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.53618\n",
            "I0820 07:06:39.152706 139671258257280 tpu_estimator.py:2160] examples/sec: 226.316\n",
            "I0820 07:06:39.154258 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 07:06:39.154475 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 07:06:40.522396 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (19, 0)\n",
            "I0820 07:07:40.631568 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (19, 252)\n",
            "I0820 07:08:40.741086 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (19, 504)\n",
            "I0820 07:09:40.850059 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (19, 756)\n",
            "I0820 07:10:39.702120 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 252000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 07:11:20.226458 139671258257280 basic_session_run_hooks.py:260] loss = 0.2485857, step = 252000 (281.076 sec)\n",
            "I0820 07:11:20.228124 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.55776\n",
            "I0820 07:11:20.228543 139671258257280 tpu_estimator.py:2160] examples/sec: 227.697\n",
            "I0820 07:11:20.230053 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 07:11:20.230233 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 07:11:21.600877 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (20, 0)\n",
            "I0820 07:12:21.707209 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (20, 252)\n",
            "I0820 07:13:21.818278 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (20, 504)\n",
            "I0820 07:14:21.929795 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (20, 756)\n",
            "I0820 07:15:20.776677 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 253000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 07:16:00.783658 139671258257280 basic_session_run_hooks.py:260] loss = 0.42423037, step = 253000 (280.557 sec)\n",
            "I0820 07:16:00.785792 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.56433\n",
            "I0820 07:16:00.786012 139671258257280 tpu_estimator.py:2160] examples/sec: 228.117\n",
            "I0820 07:16:00.788062 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 07:16:00.788380 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 07:16:02.082322 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (21, 0)\n",
            "I0820 07:17:02.191186 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (21, 252)\n",
            "I0820 07:18:02.300928 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (21, 504)\n",
            "I0820 07:19:02.410785 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (21, 756)\n",
            "I0820 07:20:01.217628 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 254000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 07:20:40.315110 139671258257280 basic_session_run_hooks.py:260] loss = 0.30664882, step = 254000 (279.531 sec)\n",
            "I0820 07:20:40.317077 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.57742\n",
            "I0820 07:20:40.317575 139671258257280 tpu_estimator.py:2160] examples/sec: 228.955\n",
            "I0820 07:20:40.318731 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 07:20:40.318945 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 07:20:41.653130 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (22, 0)\n",
            "I0820 07:21:41.756461 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (22, 252)\n",
            "I0820 07:22:41.861441 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (22, 504)\n",
            "I0820 07:23:41.967256 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (22, 756)\n",
            "I0820 07:24:40.771198 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 255000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 07:25:35.624141 139671258257280 basic_session_run_hooks.py:260] loss = 0.29915598, step = 255000 (295.309 sec)\n",
            "I0820 07:25:35.625747 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.38629\n",
            "I0820 07:25:35.626087 139671258257280 tpu_estimator.py:2160] examples/sec: 216.722\n",
            "I0820 07:25:35.627439 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 07:25:35.627611 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 07:25:36.958924 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (23, 0)\n",
            "I0820 07:26:37.066577 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (23, 252)\n",
            "I0820 07:27:37.174854 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (23, 504)\n",
            "I0820 07:28:37.283934 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (23, 756)\n",
            "I0820 07:29:36.130534 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 256000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 07:30:17.070731 139671258257280 basic_session_run_hooks.py:260] loss = 0.4867006, step = 256000 (281.447 sec)\n",
            "I0820 07:30:17.072594 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.55307\n",
            "I0820 07:30:17.073080 139671258257280 tpu_estimator.py:2160] examples/sec: 227.396\n",
            "I0820 07:30:17.074417 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 07:30:17.074613 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 07:30:18.351764 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (24, 0)\n",
            "I0820 07:31:18.463027 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (24, 252)\n",
            "I0820 07:32:18.579098 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (24, 504)\n",
            "I0820 07:33:18.695058 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (24, 756)\n",
            "I0820 07:34:17.523591 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 257000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 07:34:58.720036 139671258257280 basic_session_run_hooks.py:260] loss = 0.2582191, step = 257000 (281.649 sec)\n",
            "I0820 07:34:58.721757 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.55052\n",
            "I0820 07:34:58.721952 139671258257280 tpu_estimator.py:2160] examples/sec: 227.233\n",
            "I0820 07:34:58.723432 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 07:34:58.723606 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 07:35:00.074347 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (25, 0)\n",
            "I0820 07:36:00.184894 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (25, 252)\n",
            "I0820 07:37:00.296846 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (25, 504)\n",
            "I0820 07:38:00.409120 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (25, 756)\n",
            "I0820 07:38:59.269726 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 258000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 07:39:36.510682 139671258257280 basic_session_run_hooks.py:260] loss = 0.46422744, step = 258000 (277.791 sec)\n",
            "I0820 07:39:36.512165 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.59984\n",
            "I0820 07:39:36.512531 139671258257280 tpu_estimator.py:2160] examples/sec: 230.39\n",
            "I0820 07:39:36.514053 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 07:39:36.514219 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 07:39:37.879797 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (26, 0)\n",
            "I0820 07:40:37.983009 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (26, 252)\n",
            "I0820 07:41:38.090162 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (26, 504)\n",
            "I0820 07:42:38.197071 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (26, 756)\n",
            "I0820 07:43:37.051629 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 259000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 07:44:17.786196 139671258257280 basic_session_run_hooks.py:260] loss = 0.3004601, step = 259000 (281.275 sec)\n",
            "I0820 07:44:17.787730 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.55523\n",
            "I0820 07:44:17.788085 139671258257280 tpu_estimator.py:2160] examples/sec: 227.535\n",
            "I0820 07:44:17.789524 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 07:44:17.789674 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 07:44:19.100803 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (27, 0)\n",
            "I0820 07:45:19.204086 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (27, 252)\n",
            "I0820 07:46:19.312657 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (27, 504)\n",
            "I0820 07:47:19.420797 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (27, 756)\n",
            "I0820 07:48:18.214659 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 260000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 07:49:01.744310 139671258257280 basic_session_run_hooks.py:260] loss = 0.46037844, step = 260000 (283.958 sec)\n",
            "I0820 07:49:01.745860 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.52165\n",
            "I0820 07:49:01.746183 139671258257280 tpu_estimator.py:2160] examples/sec: 225.385\n",
            "I0820 07:49:01.747455 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 07:49:01.747604 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 07:49:03.125583 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (28, 0)\n",
            "I0820 07:50:03.234696 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (28, 252)\n",
            "I0820 07:51:03.344239 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (28, 504)\n",
            "I0820 07:52:03.454935 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (28, 756)\n",
            "I0820 07:53:02.259246 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 261000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 07:53:42.009237 139671258257280 basic_session_run_hooks.py:260] loss = 0.22325504, step = 261000 (280.265 sec)\n",
            "I0820 07:53:42.011039 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.56805\n",
            "I0820 07:53:42.011615 139671258257280 tpu_estimator.py:2160] examples/sec: 228.355\n",
            "I0820 07:53:42.013158 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 07:53:42.013339 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 07:53:43.377142 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (29, 0)\n",
            "I0820 07:54:43.481962 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (29, 252)\n",
            "I0820 07:55:43.590324 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (29, 504)\n",
            "I0820 07:56:43.698852 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (29, 756)\n",
            "I0820 07:57:42.563785 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 262000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 07:58:19.830389 139671258257280 basic_session_run_hooks.py:260] loss = 0.28853124, step = 262000 (277.821 sec)\n",
            "I0820 07:58:19.832161 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.59944\n",
            "I0820 07:58:19.832347 139671258257280 tpu_estimator.py:2160] examples/sec: 230.364\n",
            "I0820 07:58:19.833828 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 07:58:19.834129 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 07:58:21.197007 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (30, 0)\n",
            "I0820 07:59:21.304688 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (30, 252)\n",
            "I0820 08:00:21.416682 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (30, 504)\n",
            "I0820 08:01:21.529400 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (30, 756)\n",
            "I0820 08:02:20.345476 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 263000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 08:02:54.351552 139671258257280 basic_session_run_hooks.py:260] loss = 0.32608014, step = 263000 (274.521 sec)\n",
            "I0820 08:02:54.353256 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.64271\n",
            "I0820 08:02:54.353414 139671258257280 tpu_estimator.py:2160] examples/sec: 233.133\n",
            "I0820 08:02:54.354991 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 08:02:54.355206 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 08:02:55.739573 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (31, 0)\n",
            "I0820 08:03:55.843576 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (31, 252)\n",
            "I0820 08:04:55.950951 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (31, 504)\n",
            "I0820 08:05:56.057835 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (31, 756)\n",
            "I0820 08:06:54.955907 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 264000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 08:07:28.379386 139671258257280 basic_session_run_hooks.py:260] loss = 0.4630953, step = 264000 (274.028 sec)\n",
            "I0820 08:07:28.381806 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.64926\n",
            "I0820 08:07:28.382284 139671258257280 tpu_estimator.py:2160] examples/sec: 233.552\n",
            "I0820 08:07:28.383519 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 08:07:28.383695 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 08:07:29.747642 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (32, 0)\n",
            "I0820 08:08:29.849846 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (32, 252)\n",
            "I0820 08:09:29.956170 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (32, 504)\n",
            "I0820 08:10:30.063165 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (32, 756)\n",
            "I0820 08:11:28.855626 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 265000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 08:12:02.194747 139671258257280 basic_session_run_hooks.py:260] loss = 0.34901434, step = 265000 (273.815 sec)\n",
            "I0820 08:12:02.196423 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.65211\n",
            "I0820 08:12:02.196949 139671258257280 tpu_estimator.py:2160] examples/sec: 233.735\n",
            "I0820 08:12:02.198437 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 08:12:02.198613 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 08:12:03.551735 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (33, 0)\n",
            "I0820 08:13:03.659126 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (33, 252)\n",
            "I0820 08:14:03.769323 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (33, 504)\n",
            "I0820 08:15:03.878811 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (33, 756)\n",
            "I0820 08:16:02.711705 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 266000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 08:16:41.606776 139671258257280 basic_session_run_hooks.py:260] loss = 0.3854711, step = 266000 (279.412 sec)\n",
            "I0820 08:16:41.608465 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.57894\n",
            "I0820 08:16:41.608658 139671258257280 tpu_estimator.py:2160] examples/sec: 229.052\n",
            "I0820 08:16:41.609993 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 08:16:41.610146 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 08:16:42.972827 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (34, 0)\n",
            "I0820 08:17:43.081843 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (34, 252)\n",
            "I0820 08:18:43.191735 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (34, 504)\n",
            "I0820 08:19:43.302859 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (34, 756)\n",
            "I0820 08:20:42.080999 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 267000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 08:21:25.056343 139671258257280 basic_session_run_hooks.py:260] loss = 0.479196, step = 267000 (283.450 sec)\n",
            "I0820 08:21:25.058164 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.52796\n",
            "I0820 08:21:25.058784 139671258257280 tpu_estimator.py:2160] examples/sec: 225.79\n",
            "I0820 08:21:25.060235 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 08:21:25.060412 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 08:21:26.403643 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (35, 0)\n",
            "I0820 08:22:26.507300 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (35, 252)\n",
            "I0820 08:23:26.615338 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (35, 504)\n",
            "I0820 08:24:26.723672 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (35, 756)\n",
            "I0820 08:25:25.562353 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 268000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 08:26:05.845967 139671258257280 basic_session_run_hooks.py:260] loss = 0.33362636, step = 268000 (280.790 sec)\n",
            "I0820 08:26:05.848050 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.56138\n",
            "I0820 08:26:05.848712 139671258257280 tpu_estimator.py:2160] examples/sec: 227.929\n",
            "I0820 08:26:05.850561 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 08:26:05.850813 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 08:26:07.177504 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (36, 0)\n",
            "I0820 08:27:07.281065 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (36, 252)\n",
            "I0820 08:28:07.389407 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (36, 504)\n",
            "I0820 08:29:07.497821 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (36, 756)\n",
            "I0820 08:30:06.285506 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 269000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 08:30:50.155690 139671258257280 basic_session_run_hooks.py:260] loss = 0.25768068, step = 269000 (284.310 sec)\n",
            "I0820 08:30:50.157640 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.51729\n",
            "I0820 08:30:50.158183 139671258257280 tpu_estimator.py:2160] examples/sec: 225.107\n",
            "I0820 08:30:50.159730 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 08:30:50.159911 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 08:30:51.512108 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (37, 0)\n",
            "I0820 08:31:51.623439 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (37, 252)\n",
            "I0820 08:32:51.734661 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (37, 504)\n",
            "I0820 08:33:51.846759 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (37, 756)\n",
            "I0820 08:34:50.707179 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 270000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 08:35:30.298348 139671258257280 basic_session_run_hooks.py:260] loss = 0.48710313, step = 270000 (280.143 sec)\n",
            "I0820 08:35:30.299950 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.56961\n",
            "I0820 08:35:30.300420 139671258257280 tpu_estimator.py:2160] examples/sec: 228.455\n",
            "I0820 08:35:30.301747 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 08:35:30.301939 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 08:35:31.676235 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (38, 0)\n",
            "I0820 08:36:31.783593 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (38, 252)\n",
            "I0820 08:37:31.892325 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (38, 504)\n",
            "I0820 08:38:32.001255 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (38, 756)\n",
            "I0820 08:39:30.841852 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 271000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 08:40:06.925276 139671258257280 basic_session_run_hooks.py:260] loss = 0.3501492, step = 271000 (276.627 sec)\n",
            "I0820 08:40:06.926938 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.61498\n",
            "I0820 08:40:06.927350 139671258257280 tpu_estimator.py:2160] examples/sec: 231.358\n",
            "I0820 08:40:06.928608 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 08:40:06.928761 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 08:40:08.217084 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (39, 0)\n",
            "I0820 08:41:08.323382 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (39, 252)\n",
            "I0820 08:42:08.429705 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (39, 504)\n",
            "I0820 08:43:08.537962 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (39, 756)\n",
            "I0820 08:44:07.368023 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 272000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 08:44:42.789751 139671258257280 basic_session_run_hooks.py:260] loss = 0.20807698, step = 272000 (275.864 sec)\n",
            "I0820 08:44:42.791067 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.62497\n",
            "I0820 08:44:42.791525 139671258257280 tpu_estimator.py:2160] examples/sec: 231.998\n",
            "I0820 08:44:42.793058 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 08:44:42.793486 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 08:44:44.175792 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (40, 0)\n",
            "I0820 08:45:44.285999 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (40, 252)\n",
            "I0820 08:46:44.397421 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (40, 504)\n",
            "I0820 08:47:44.508913 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (40, 756)\n",
            "I0820 08:48:43.352735 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 273000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 08:49:18.788410 139671258257280 basic_session_run_hooks.py:260] loss = 0.12162428, step = 273000 (275.999 sec)\n",
            "I0820 08:49:18.789911 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.6232\n",
            "I0820 08:49:18.790098 139671258257280 tpu_estimator.py:2160] examples/sec: 231.885\n",
            "I0820 08:49:18.791356 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 08:49:18.791538 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 08:49:20.171155 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (41, 0)\n",
            "I0820 08:50:20.278582 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (41, 252)\n",
            "I0820 08:51:20.388859 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (41, 504)\n",
            "I0820 08:52:20.499239 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (41, 756)\n",
            "I0820 08:53:19.324355 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 274000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 08:53:59.869370 139671258257280 basic_session_run_hooks.py:260] loss = 0.18902333, step = 274000 (281.081 sec)\n",
            "I0820 08:53:59.870813 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.55769\n",
            "I0820 08:53:59.871340 139671258257280 tpu_estimator.py:2160] examples/sec: 227.692\n",
            "I0820 08:53:59.872580 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 08:53:59.872767 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 08:54:01.217259 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (42, 0)\n",
            "I0820 08:55:01.327531 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (42, 252)\n",
            "I0820 08:56:01.439601 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (42, 504)\n",
            "I0820 08:57:01.553441 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (42, 756)\n",
            "I0820 08:58:00.348860 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 275000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 08:58:36.746682 139671258257280 basic_session_run_hooks.py:260] loss = 0.1756149, step = 275000 (276.877 sec)\n",
            "I0820 08:58:36.748537 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.6117\n",
            "I0820 08:58:36.748696 139671258257280 tpu_estimator.py:2160] examples/sec: 231.149\n",
            "I0820 08:58:36.749896 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 08:58:36.750071 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 08:58:38.121225 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (43, 0)\n",
            "I0820 08:59:38.232095 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (43, 252)\n",
            "I0820 09:00:38.339649 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (43, 504)\n",
            "I0820 09:01:38.449325 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (43, 756)\n",
            "I0820 09:02:37.303382 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 276000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 09:03:17.380638 139671258257280 basic_session_run_hooks.py:260] loss = 0.16160493, step = 276000 (280.634 sec)\n",
            "I0820 09:03:17.382333 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.56336\n",
            "I0820 09:03:17.382489 139671258257280 tpu_estimator.py:2160] examples/sec: 228.055\n",
            "I0820 09:03:17.383949 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 09:03:17.384133 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 09:03:18.760384 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (44, 0)\n",
            "I0820 09:04:18.864586 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (44, 252)\n",
            "I0820 09:05:18.973188 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (44, 504)\n",
            "I0820 09:06:19.081263 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (44, 756)\n",
            "I0820 09:07:17.932361 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 277000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 09:08:05.584712 139671258257280 basic_session_run_hooks.py:260] loss = 0.12508416, step = 277000 (288.204 sec)\n",
            "I0820 09:08:05.586319 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.46976\n",
            "I0820 09:08:05.586783 139671258257280 tpu_estimator.py:2160] examples/sec: 222.065\n",
            "I0820 09:08:05.588092 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 09:08:05.588253 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 09:08:06.894431 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (45, 0)\n",
            "I0820 09:09:06.999946 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (45, 252)\n",
            "I0820 09:10:07.110944 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (45, 504)\n",
            "I0820 09:11:07.221404 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (45, 756)\n",
            "I0820 09:12:06.064684 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 278000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 09:12:46.745333 139671258257280 basic_session_run_hooks.py:260] loss = 0.29160437, step = 278000 (281.161 sec)\n",
            "I0820 09:12:46.746809 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.55669\n",
            "I0820 09:12:46.747346 139671258257280 tpu_estimator.py:2160] examples/sec: 227.628\n",
            "I0820 09:12:46.748944 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 09:12:46.749143 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 09:12:48.105406 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (46, 0)\n",
            "I0820 09:13:48.216945 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (46, 252)\n",
            "I0820 09:14:48.329255 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (46, 504)\n",
            "I0820 09:15:48.440864 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (46, 756)\n",
            "I0820 09:16:47.334032 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 279000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 09:17:26.834666 139671258257280 basic_session_run_hooks.py:260] loss = 0.14738518, step = 279000 (280.089 sec)\n",
            "I0820 09:17:26.836486 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.57029\n",
            "I0820 09:17:26.837054 139671258257280 tpu_estimator.py:2160] examples/sec: 228.498\n",
            "I0820 09:17:26.838435 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 09:17:26.838621 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 09:17:28.206395 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (47, 0)\n",
            "I0820 09:18:28.311187 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (47, 252)\n",
            "I0820 09:19:28.418594 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (47, 504)\n",
            "I0820 09:20:28.524776 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (47, 756)\n",
            "I0820 09:21:27.360113 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 280000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 09:22:07.683445 139671258257280 basic_session_run_hooks.py:260] loss = 0.34708035, step = 280000 (280.849 sec)\n",
            "I0820 09:22:07.685297 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.56064\n",
            "I0820 09:22:07.685511 139671258257280 tpu_estimator.py:2160] examples/sec: 227.881\n",
            "I0820 09:22:07.687073 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 09:22:07.687301 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 09:22:09.040144 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (48, 0)\n",
            "I0820 09:23:09.144723 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (48, 252)\n",
            "I0820 09:24:09.252657 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (48, 504)\n",
            "I0820 09:25:09.361280 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (48, 756)\n",
            "I0820 09:26:08.206116 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 281000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 09:26:49.510365 139671258257280 basic_session_run_hooks.py:260] loss = 0.4435936, step = 281000 (281.827 sec)\n",
            "I0820 09:26:49.511893 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.54828\n",
            "I0820 09:26:49.512383 139671258257280 tpu_estimator.py:2160] examples/sec: 227.09\n",
            "I0820 09:26:49.513566 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 09:26:49.513760 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 09:26:50.921694 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (49, 0)\n",
            "I0820 09:27:51.026698 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (49, 252)\n",
            "I0820 09:28:51.132940 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (49, 504)\n",
            "I0820 09:29:51.239698 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (49, 756)\n",
            "I0820 09:30:50.036318 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 282000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 09:31:22.670532 139671258257280 basic_session_run_hooks.py:260] loss = 0.3387942, step = 282000 (273.160 sec)\n",
            "I0820 09:31:22.672336 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.66085\n",
            "I0820 09:31:22.672746 139671258257280 tpu_estimator.py:2160] examples/sec: 234.295\n",
            "I0820 09:31:22.674320 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 09:31:22.674525 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 09:31:24.050564 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (50, 0)\n",
            "I0820 09:32:24.160144 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (50, 252)\n",
            "I0820 09:33:24.271492 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (50, 504)\n",
            "I0820 09:34:24.380886 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (50, 756)\n",
            "I0820 09:35:23.186461 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 283000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 09:36:03.035507 139671258257280 basic_session_run_hooks.py:260] loss = 0.20217645, step = 283000 (280.365 sec)\n",
            "I0820 09:36:03.037597 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.56678\n",
            "I0820 09:36:03.038217 139671258257280 tpu_estimator.py:2160] examples/sec: 228.274\n",
            "I0820 09:36:03.040342 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 09:36:03.040586 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 09:36:04.436866 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (51, 0)\n",
            "I0820 09:37:04.544549 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (51, 252)\n",
            "I0820 09:38:04.654859 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (51, 504)\n",
            "I0820 09:39:04.764570 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (51, 756)\n",
            "I0820 09:40:03.579704 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 284000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 09:40:39.898872 139671258257280 basic_session_run_hooks.py:260] loss = 0.47306818, step = 284000 (276.863 sec)\n",
            "I0820 09:40:39.900831 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.61189\n",
            "I0820 09:40:39.901238 139671258257280 tpu_estimator.py:2160] examples/sec: 231.161\n",
            "I0820 09:40:39.902559 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 09:40:39.902723 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 09:40:41.280840 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (52, 0)\n",
            "I0820 09:41:41.390183 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (52, 252)\n",
            "I0820 09:42:41.500926 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (52, 504)\n",
            "I0820 09:43:41.609842 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (52, 756)\n",
            "I0820 09:44:40.415516 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 285000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 09:45:20.140003 139671258257280 basic_session_run_hooks.py:260] loss = 0.28538892, step = 285000 (280.241 sec)\n",
            "I0820 09:45:20.141878 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.56836\n",
            "I0820 09:45:20.142322 139671258257280 tpu_estimator.py:2160] examples/sec: 228.375\n",
            "I0820 09:45:20.143664 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 09:45:20.143856 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 09:45:21.531226 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (53, 0)\n",
            "I0820 09:46:21.636053 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (53, 252)\n",
            "I0820 09:47:21.742557 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (53, 504)\n",
            "I0820 09:48:21.848400 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (53, 756)\n",
            "I0820 09:49:20.682583 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 286000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 09:50:00.727804 139671258257280 basic_session_run_hooks.py:260] loss = 0.1546218, step = 286000 (280.588 sec)\n",
            "I0820 09:50:00.729756 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.56395\n",
            "I0820 09:50:00.730341 139671258257280 tpu_estimator.py:2160] examples/sec: 228.093\n",
            "I0820 09:50:00.732026 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 09:50:00.732243 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 09:50:02.110513 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (54, 0)\n",
            "I0820 09:51:02.214584 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (54, 252)\n",
            "I0820 09:52:02.321225 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (54, 504)\n",
            "I0820 09:53:02.426741 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (54, 756)\n",
            "I0820 09:54:01.259654 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 287000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 09:54:33.772139 139671258257280 basic_session_run_hooks.py:260] loss = 0.29019833, step = 287000 (273.044 sec)\n",
            "I0820 09:54:33.773648 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.66241\n",
            "I0820 09:54:33.773823 139671258257280 tpu_estimator.py:2160] examples/sec: 234.394\n",
            "I0820 09:54:33.775964 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 09:54:33.776174 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 09:54:35.174415 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (55, 0)\n",
            "I0820 09:55:35.278621 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (55, 252)\n",
            "I0820 09:56:35.383888 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (55, 504)\n",
            "I0820 09:57:35.488720 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (55, 756)\n",
            "I0820 09:58:34.347259 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 288000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 09:59:11.111304 139671258257280 basic_session_run_hooks.py:260] loss = 0.525719, step = 288000 (277.339 sec)\n",
            "I0820 09:59:11.113047 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.60569\n",
            "I0820 09:59:11.113404 139671258257280 tpu_estimator.py:2160] examples/sec: 230.764\n",
            "I0820 09:59:11.114751 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 09:59:11.114926 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 09:59:12.514382 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (56, 0)\n",
            "I0820 10:00:12.623603 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (56, 252)\n",
            "I0820 10:01:12.734106 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (56, 504)\n",
            "I0820 10:02:12.843909 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (56, 756)\n",
            "I0820 10:03:11.630864 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 289000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 10:03:50.542139 139671258257280 basic_session_run_hooks.py:260] loss = 0.31680405, step = 289000 (279.431 sec)\n",
            "I0820 10:03:50.544029 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.5787\n",
            "I0820 10:03:50.544281 139671258257280 tpu_estimator.py:2160] examples/sec: 229.037\n",
            "I0820 10:03:50.545873 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 10:03:50.546150 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 10:03:51.919915 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (57, 0)\n",
            "I0820 10:04:52.028549 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (57, 252)\n",
            "I0820 10:05:52.138709 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (57, 504)\n",
            "I0820 10:06:52.249070 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (57, 756)\n",
            "I0820 10:07:51.098178 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 290000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 10:08:24.020286 139671258257280 basic_session_run_hooks.py:260] loss = 0.21999966, step = 290000 (273.478 sec)\n",
            "I0820 10:08:24.021911 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.6566\n",
            "I0820 10:08:24.022114 139671258257280 tpu_estimator.py:2160] examples/sec: 234.023\n",
            "I0820 10:08:24.023638 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 10:08:24.023865 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 10:08:25.403638 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (58, 0)\n",
            "I0820 10:09:25.507836 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (58, 252)\n",
            "I0820 10:10:25.613878 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (58, 504)\n",
            "I0820 10:11:25.720050 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (58, 756)\n",
            "I0820 10:12:24.548858 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 291000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 10:13:02.509504 139671258257280 basic_session_run_hooks.py:260] loss = 0.44598246, step = 291000 (278.489 sec)\n",
            "I0820 10:13:02.511109 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.5908\n",
            "I0820 10:13:02.511323 139671258257280 tpu_estimator.py:2160] examples/sec: 229.811\n",
            "I0820 10:13:02.513010 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 10:13:02.513229 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 10:13:03.885848 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (59, 0)\n",
            "I0820 10:14:03.992757 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (59, 252)\n",
            "I0820 10:15:04.102993 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (59, 504)\n",
            "I0820 10:16:04.214187 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (59, 756)\n",
            "I0820 10:17:03.020252 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 292000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 10:17:36.236252 139671258257280 basic_session_run_hooks.py:260] loss = 0.43764064, step = 292000 (273.727 sec)\n",
            "I0820 10:17:36.238131 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.65327\n",
            "I0820 10:17:36.238558 139671258257280 tpu_estimator.py:2160] examples/sec: 233.81\n",
            "I0820 10:17:36.240128 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 10:17:36.240304 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 10:17:37.606251 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (60, 0)\n",
            "I0820 10:18:37.714643 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (60, 252)\n",
            "I0820 10:19:37.824747 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (60, 504)\n",
            "I0820 10:20:37.934930 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (60, 756)\n",
            "I0820 10:21:36.811128 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 293000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 10:22:11.083642 139671258257280 basic_session_run_hooks.py:260] loss = 0.3656915, step = 293000 (274.847 sec)\n",
            "I0820 10:22:11.085301 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.63839\n",
            "I0820 10:22:11.085520 139671258257280 tpu_estimator.py:2160] examples/sec: 232.857\n",
            "I0820 10:22:11.087054 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 10:22:11.087229 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 10:22:12.467697 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (61, 0)\n",
            "I0820 10:23:12.574872 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (61, 252)\n",
            "I0820 10:24:12.682840 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (61, 504)\n",
            "I0820 10:25:12.790246 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (61, 756)\n",
            "I0820 10:26:11.642577 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 294000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 10:26:49.875753 139671258257280 basic_session_run_hooks.py:260] loss = 0.18356001, step = 294000 (278.792 sec)\n",
            "I0820 10:26:49.877700 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.5869\n",
            "I0820 10:26:49.877916 139671258257280 tpu_estimator.py:2160] examples/sec: 229.561\n",
            "I0820 10:26:49.879180 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 10:26:49.879350 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 10:26:51.252920 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (62, 0)\n",
            "I0820 10:27:51.359701 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (62, 252)\n",
            "I0820 10:28:51.467272 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (62, 504)\n",
            "I0820 10:29:51.574996 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (62, 756)\n",
            "I0820 10:30:50.430419 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 295000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 10:31:24.442759 139671258257280 basic_session_run_hooks.py:260] loss = 0.52031463, step = 295000 (274.567 sec)\n",
            "I0820 10:31:24.444507 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.6421\n",
            "I0820 10:31:24.444697 139671258257280 tpu_estimator.py:2160] examples/sec: 233.094\n",
            "I0820 10:31:24.446573 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 10:31:24.446766 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 10:31:25.718790 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (63, 0)\n",
            "I0820 10:32:25.828710 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (63, 252)\n",
            "I0820 10:33:25.937054 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (63, 504)\n",
            "I0820 10:34:26.044647 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (63, 756)\n",
            "I0820 10:35:24.869562 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 296000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 10:36:03.551395 139671258257280 basic_session_run_hooks.py:260] loss = 0.20524025, step = 296000 (279.109 sec)\n",
            "I0820 10:36:03.553077 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.58284\n",
            "I0820 10:36:03.553258 139671258257280 tpu_estimator.py:2160] examples/sec: 229.301\n",
            "I0820 10:36:03.554610 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 10:36:03.554802 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 10:36:04.941083 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (64, 0)\n",
            "I0820 10:37:05.045795 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (64, 252)\n",
            "I0820 10:38:05.155612 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (64, 504)\n",
            "I0820 10:39:05.264569 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (64, 756)\n",
            "I0820 10:40:04.095840 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 297000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 10:40:38.839770 139671258257280 basic_session_run_hooks.py:260] loss = 0.30635193, step = 297000 (275.288 sec)\n",
            "I0820 10:40:38.841496 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.63255\n",
            "I0820 10:40:38.841890 139671258257280 tpu_estimator.py:2160] examples/sec: 232.483\n",
            "I0820 10:40:38.843203 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 10:40:38.843365 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 10:40:40.232619 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (65, 0)\n",
            "I0820 10:41:40.341539 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (65, 252)\n",
            "I0820 10:42:40.449724 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (65, 504)\n",
            "I0820 10:43:40.557707 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (65, 756)\n",
            "I0820 10:44:39.436480 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 298000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 10:45:16.277027 139671258257280 basic_session_run_hooks.py:260] loss = 0.19935812, step = 298000 (277.437 sec)\n",
            "I0820 10:45:16.278728 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.60442\n",
            "I0820 10:45:16.279046 139671258257280 tpu_estimator.py:2160] examples/sec: 230.683\n",
            "I0820 10:45:16.280501 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 10:45:16.280704 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 10:45:17.641942 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (66, 0)\n",
            "I0820 10:46:17.753958 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (66, 252)\n",
            "I0820 10:47:17.863721 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (66, 504)\n",
            "I0820 10:48:17.975565 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (66, 756)\n",
            "I0820 10:49:16.831899 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 299000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 10:49:59.274259 139671258257280 basic_session_run_hooks.py:260] loss = 0.18968819, step = 299000 (282.997 sec)\n",
            "I0820 10:49:59.276024 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.5336\n",
            "I0820 10:49:59.276230 139671258257280 tpu_estimator.py:2160] examples/sec: 226.151\n",
            "I0820 10:49:59.277631 139671258257280 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0820 10:49:59.277812 139671258257280 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0820 10:50:00.685385 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (67, 0)\n",
            "I0820 10:51:00.794125 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (67, 252)\n",
            "I0820 10:52:00.904357 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (67, 504)\n",
            "I0820 10:53:01.013287 139670084032256 tpu_estimator.py:275] Outfeed finished for iteration (67, 756)\n",
            "I0820 10:53:59.894587 139671258257280 basic_session_run_hooks.py:606] Saving checkpoints for 300000 into gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt.\n",
            "I0820 10:54:33.069002 139671258257280 basic_session_run_hooks.py:260] loss = 0.2415969, step = 300000 (273.795 sec)\n",
            "I0820 10:54:33.070867 139671258257280 tpu_estimator.py:2159] global_step/sec: 3.65237\n",
            "I0820 10:54:33.071472 139671258257280 tpu_estimator.py:2160] examples/sec: 233.752\n",
            "I0820 10:54:34.906486 139671258257280 tpu_estimator.py:598] Stop infeed thread controller\n",
            "I0820 10:54:34.906802 139671258257280 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
            "I0820 10:54:34.907147 139670110246656 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
            "I0820 10:54:34.907456 139670110246656 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
            "I0820 10:54:34.907673 139671258257280 error_handling.py:96] infeed marked as finished\n",
            "I0820 10:54:34.907833 139671258257280 tpu_estimator.py:602] Stop output thread controller\n",
            "I0820 10:54:34.907892 139671258257280 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
            "I0820 10:54:34.908038 139670084032256 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
            "I0820 10:54:34.908109 139670084032256 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
            "I0820 10:54:34.908998 139671258257280 error_handling.py:96] outfeed marked as finished\n",
            "I0820 10:54:34.909178 139671258257280 tpu_estimator.py:606] Shutdown TPU system.\n",
            "I0820 10:54:36.604552 139671258257280 estimator.py:368] Loss for final step: 0.2415969.\n",
            "I0820 10:54:36.605884 139671258257280 error_handling.py:96] training_loop marked as finished\n",
            "I0820 10:54:36.606082 139671258257280 run_pretraining.py:469] ***** Running evaluation *****\n",
            "I0820 10:54:36.606175 139671258257280 run_pretraining.py:470]   Batch size = 8\n",
            "I0820 10:54:37.591130 139671258257280 estimator.py:1145] Calling model_fn.\n",
            "I0820 10:54:37.694526 139671258257280 run_pretraining.py:117] *** Features ***\n",
            "I0820 10:54:37.694842 139671258257280 run_pretraining.py:119]   name = input_ids, shape = (1, 512)\n",
            "I0820 10:54:37.694938 139671258257280 run_pretraining.py:119]   name = input_mask, shape = (1, 512)\n",
            "I0820 10:54:37.695037 139671258257280 run_pretraining.py:119]   name = masked_lm_ids, shape = (1, 20)\n",
            "I0820 10:54:37.695115 139671258257280 run_pretraining.py:119]   name = masked_lm_positions, shape = (1, 20)\n",
            "I0820 10:54:37.695199 139671258257280 run_pretraining.py:119]   name = masked_lm_weights, shape = (1, 20)\n",
            "I0820 10:54:37.695261 139671258257280 run_pretraining.py:119]   name = next_sentence_labels, shape = (1, 1)\n",
            "I0820 10:54:37.695322 139671258257280 run_pretraining.py:119]   name = segment_ids, shape = (1, 512)\n",
            "I0820 10:54:40.617224 139671258257280 run_pretraining.py:167] **** Trainable Variables ****\n",
            "I0820 10:54:40.617471 139671258257280 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (30522, 768)\n",
            "I0820 10:54:40.617593 139671258257280 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "I0820 10:54:40.617688 139671258257280 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "I0820 10:54:40.617774 139671258257280 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.617867 139671258257280 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.617950 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.618053 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 10:54:40.618135 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.618216 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 10:54:40.618291 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.618372 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 10:54:40.618448 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.618525 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.618600 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.618674 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.618748 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 10:54:40.618834 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 10:54:40.618910 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 10:54:40.619003 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.619081 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.619156 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.619230 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.619308 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 10:54:40.619384 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.619461 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 10:54:40.619536 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.619613 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 10:54:40.619688 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.619766 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.619845 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.619920 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.620004 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 10:54:40.620083 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 10:54:40.620157 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 10:54:40.620235 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.620309 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.620385 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.620459 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.620538 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 10:54:40.620612 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.620700 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 10:54:40.620775 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.620858 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 10:54:40.620935 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.621026 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.621101 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.621176 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.621252 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 10:54:40.621332 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 10:54:40.621409 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 10:54:40.621487 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.621562 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.621635 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.621711 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.621791 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 10:54:40.621873 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.621958 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 10:54:40.622064 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.622157 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 10:54:40.622232 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.622310 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.622387 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.622460 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.622535 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 10:54:40.622612 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 10:54:40.622689 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 10:54:40.622766 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.622884 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.622961 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.623051 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.623130 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 10:54:40.623204 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.623290 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 10:54:40.623369 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.623450 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 10:54:40.623524 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.623602 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.623677 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.623752 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.623832 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 10:54:40.623912 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 10:54:40.624001 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 10:54:40.624083 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.624158 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.624232 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.624307 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.624396 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 10:54:40.624473 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.624552 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 10:54:40.624626 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.624705 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 10:54:40.624779 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.624865 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.624938 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.625028 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.625103 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 10:54:40.625182 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 10:54:40.625256 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 10:54:40.625336 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.625411 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.625486 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.625561 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.625639 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 10:54:40.625712 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.625789 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 10:54:40.625870 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.625948 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 10:54:40.626038 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.626116 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.626190 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.626264 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.626340 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 10:54:40.626422 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 10:54:40.626499 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 10:54:40.626577 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.626652 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.626726 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.626801 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.626885 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 10:54:40.626959 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.627052 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 10:54:40.627128 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.627205 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 10:54:40.716048 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.716327 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.716455 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.716566 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.716668 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 10:54:40.716781 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 10:54:40.716899 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 10:54:40.717028 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.717135 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.717235 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.717335 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.717441 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 10:54:40.717540 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.717648 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 10:54:40.717752 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.717871 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 10:54:40.717994 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.718110 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.718217 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.718327 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.718431 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 10:54:40.718539 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 10:54:40.718644 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 10:54:40.718753 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.718889 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.719020 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.719130 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.719244 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 10:54:40.719346 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.719452 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 10:54:40.719556 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.719665 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 10:54:40.719768 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.719910 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.720060 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.720168 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.720296 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 10:54:40.720410 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 10:54:40.720517 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 10:54:40.720624 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.720740 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.720852 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.720957 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.721086 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 10:54:40.721192 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.721302 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 10:54:40.721406 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.721511 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 10:54:40.721613 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.721720 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.721834 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.721938 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.722065 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 10:54:40.722177 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 10:54:40.722278 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 10:54:40.722383 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.722487 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.722589 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.722698 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.722824 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "I0820 10:54:40.722931 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.723059 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "I0820 10:54:40.723165 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.723273 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "I0820 10:54:40.723378 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.723483 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.723583 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.723686 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.723787 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0820 10:54:40.723905 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0820 10:54:40.724049 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0820 10:54:40.724199 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.724317 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.724421 139671258257280 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.724522 139671258257280 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.724631 139671258257280 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.724734 139671258257280 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
            "I0820 10:54:40.724848 139671258257280 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
            "I0820 10:54:40.724952 139671258257280 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
            "I0820 10:54:40.725075 139671258257280 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
            "I0820 10:54:40.725176 139671258257280 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (30522,)\n",
            "I0820 10:54:40.725279 139671258257280 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
            "I0820 10:54:40.725383 139671258257280 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
            "W0820 10:54:41.143381 139671258257280 deprecation_wrapper.py:119] From run_pretraining.py:198: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "W0820 10:54:41.161081 139671258257280 deprecation_wrapper.py:119] From run_pretraining.py:202: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "I0820 10:54:42.218288 139671258257280 estimator.py:1147] Done calling model_fn.\n",
            "I0820 10:54:42.237371 139671258257280 evaluation.py:255] Starting evaluation at 2019-08-20T10:54:42Z\n",
            "I0820 10:54:42.237634 139671258257280 tpu_estimator.py:499] TPU job name worker\n",
            "I0820 10:54:42.769169 139671258257280 monitored_session.py:240] Graph was finalized.\n",
            "I0820 10:54:43.017719 139671258257280 saver.py:1280] Restoring parameters from gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt-300000\n",
            "I0820 10:55:17.232436 139671258257280 session_manager.py:500] Running local_init_op.\n",
            "I0820 10:55:17.433991 139671258257280 session_manager.py:502] Done running local_init_op.\n",
            "I0820 10:55:17.875241 139671258257280 tpu_estimator.py:557] Init TPU system\n",
            "I0820 10:55:26.713680 139671258257280 tpu_estimator.py:566] Initialized TPU in 8 seconds\n",
            "I0820 10:55:26.714454 139670066460416 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "I0820 10:55:26.714807 139670058067712 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "I0820 10:55:26.926058 139671258257280 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "I0820 10:55:27.106697 139671258257280 tpu_estimator.py:590] Enqueue next (100) batch(es) of data to infeed.\n",
            "I0820 10:55:27.107122 139671258257280 tpu_estimator.py:594] Dequeue next (100) batch(es) of data from outfeed.\n",
            "I0820 10:55:32.959612 139670058067712 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "I0820 10:55:35.819611 139671258257280 evaluation.py:167] Evaluation [100/100]\n",
            "I0820 10:55:35.819940 139671258257280 tpu_estimator.py:598] Stop infeed thread controller\n",
            "I0820 10:55:35.820075 139671258257280 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
            "I0820 10:55:35.820247 139670066460416 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
            "I0820 10:55:35.820368 139670066460416 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
            "I0820 10:55:35.820502 139671258257280 error_handling.py:96] infeed marked as finished\n",
            "I0820 10:55:35.820617 139671258257280 tpu_estimator.py:602] Stop output thread controller\n",
            "I0820 10:55:35.820683 139671258257280 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
            "I0820 10:55:36.825086 139670058067712 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
            "I0820 10:55:36.825339 139670058067712 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
            "I0820 10:55:36.825499 139671258257280 error_handling.py:96] outfeed marked as finished\n",
            "I0820 10:55:36.825643 139671258257280 tpu_estimator.py:606] Shutdown TPU system.\n",
            "I0820 10:55:37.416869 139671258257280 evaluation.py:275] Finished evaluation at 2019-08-20-10:55:37\n",
            "I0820 10:55:37.417234 139671258257280 estimator.py:2039] Saving dict for global step 300000: global_step = 300000, loss = 0.19169405, masked_lm_accuracy = 0.95320743, masked_lm_loss = 0.16689053, next_sentence_accuracy = 1.0, next_sentence_loss = 4.6706875e-05\n",
            "I0820 10:55:41.012012 139671258257280 estimator.py:2099] Saving 'checkpoint_path' summary for global step 300000: gs://yohei-kikuta/mlstudy-phys/patent-analysis/patent-2017-pretrain-BERT/model.ckpt-300000\n",
            "I0820 10:55:42.340308 139671258257280 error_handling.py:96] evaluation_loop marked as finished\n",
            "I0820 10:55:42.340659 139671258257280 run_pretraining.py:483] ***** Eval results *****\n",
            "I0820 10:55:42.340777 139671258257280 run_pretraining.py:485]   global_step = 300000\n",
            "I0820 10:55:42.341297 139671258257280 run_pretraining.py:485]   loss = 0.19169405\n",
            "I0820 10:55:42.341431 139671258257280 run_pretraining.py:485]   masked_lm_accuracy = 0.95320743\n",
            "I0820 10:55:42.341532 139671258257280 run_pretraining.py:485]   masked_lm_loss = 0.16689053\n",
            "I0820 10:55:42.341613 139671258257280 run_pretraining.py:485]   next_sentence_accuracy = 1.0\n",
            "I0820 10:55:42.341696 139671258257280 run_pretraining.py:485]   next_sentence_loss = 4.6706875e-05\n",
            "CPU times: user 1min 38s, sys: 15.4 s, total: 1min 53s\n",
            "Wall time: 5h 20min 8s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lfxg-o6vLR0",
        "colab_type": "text"
      },
      "source": [
        "## Memo (train3000 + grants6000)\n",
        "\n",
        "```\n",
        "I0811 12:50:14.190979 140514602837888 run_pretraining.py:483] ***** Eval results *****\n",
        "I0811 12:50:14.191113 140514602837888 run_pretraining.py:485]   global_step = 20\n",
        "I0811 12:50:14.191493 140514602837888 run_pretraining.py:485]   loss = 1.0284224\n",
        "I0811 12:50:14.191617 140514602837888 run_pretraining.py:485]   masked_lm_accuracy = 0.8165625\n",
        "I0811 12:50:14.191753 140514602837888 run_pretraining.py:485]   masked_lm_loss = 0.86381125\n",
        "I0811 12:50:14.191835 140514602837888 run_pretraining.py:485]   next_sentence_accuracy = 0.95\n",
        "I0811 12:50:14.191914 140514602837888 run_pretraining.py:485]   next_sentence_loss = 0.1793103\n",
        "CPU times: user 1.56 s, sys: 244 ms, total: 1.8 s\n",
        "Wall time: 4min 17s\n",
        "```\n",
        "\n",
        "```\n",
        "I0811 14:17:34.821915 139717559273344 run_pretraining.py:483] ***** Eval results *****\n",
        "I0811 14:17:34.822047 139717559273344 run_pretraining.py:485]   global_step = 15000\n",
        "I0811 14:17:34.822362 139717559273344 run_pretraining.py:485]   loss = 0.18834595\n",
        "I0811 14:17:34.822492 139717559273344 run_pretraining.py:485]   masked_lm_accuracy = 0.9595625\n",
        "I0811 14:17:34.822575 139717559273344 run_pretraining.py:485]   masked_lm_loss = 0.14227556\n",
        "I0811 14:17:34.822673 139717559273344 run_pretraining.py:485]   next_sentence_accuracy = 0.99875\n",
        "I0811 14:17:34.822756 139717559273344 run_pretraining.py:485]   next_sentence_loss = 0.0048195585\n",
        "```\n",
        "\n",
        "```\n",
        "I0812 03:15:34.621796 140024347654016 run_pretraining.py:483] ***** Eval results *****\n",
        "I0812 03:15:34.621907 140024347654016 run_pretraining.py:485]   global_step = 70000\n",
        "I0812 03:15:34.622360 140024347654016 run_pretraining.py:485]   loss = 0.0005139347\n",
        "I0812 03:15:34.622489 140024347654016 run_pretraining.py:485]   masked_lm_accuracy = 0.9999375\n",
        "I0812 03:15:34.622562 140024347654016 run_pretraining.py:485]   masked_lm_loss = 0.00031679025\n",
        "I0812 03:15:34.622630 140024347654016 run_pretraining.py:485]   next_sentence_accuracy = 1.0\n",
        "I0812 03:15:34.622724 140024347654016 run_pretraining.py:485]   next_sentence_loss = 1.9996969e-07\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svlb3YSXhpS8",
        "colab_type": "text"
      },
      "source": [
        "## Memo (patent-2017 data)\n",
        "\n",
        "```\n",
        "I0818 07:42:20.731508 140399826028416 run_pretraining.py:483] ***** Eval results *****\n",
        "I0818 07:42:20.731633 140399826028416 run_pretraining.py:485]   global_step = 10000\n",
        "I0818 07:42:20.731997 140399826028416 run_pretraining.py:485]   loss = 0.53506017\n",
        "I0818 07:42:20.732118 140399826028416 run_pretraining.py:485]   masked_lm_accuracy = 0.88384515\n",
        "I0818 07:42:20.732220 140399826028416 run_pretraining.py:485]   masked_lm_loss = 0.4997728\n",
        "I0818 07:42:20.732293 140399826028416 run_pretraining.py:485]   next_sentence_accuracy = 0.99\n",
        "I0818 07:42:20.732356 140399826028416 run_pretraining.py:485]   next_sentence_loss = 0.02872859\n",
        "CPU times: user 14.9 s, sys: 2.67 s, total: 17.6 s\n",
        "Wall time: 50min 5s\n",
        "```\n",
        "\n",
        "```\n",
        "I0818 08:36:06.739647 140538574493568 error_handling.py:96] evaluation_loop marked as finished\n",
        "I0818 08:36:06.740006 140538574493568 run_pretraining.py:483] ***** Eval results *****\n",
        "I0818 08:36:06.740121 140538574493568 run_pretraining.py:485]   global_step = 20000\n",
        "I0818 08:36:06.740490 140538574493568 run_pretraining.py:485]   loss = 0.39322364\n",
        "I0818 08:36:06.740602 140538574493568 run_pretraining.py:485]   masked_lm_accuracy = 0.9102295\n",
        "I0818 08:36:06.740676 140538574493568 run_pretraining.py:485]   masked_lm_loss = 0.36800206\n",
        "I0818 08:36:06.740731 140538574493568 run_pretraining.py:485]   next_sentence_accuracy = 0.99875\n",
        "I0818 08:36:06.740785 140538574493568 run_pretraining.py:485]   next_sentence_loss = 0.006405907\n",
        "CPU times: user 13.8 s, sys: 2.64 s, total: 16.4 s\n",
        "Wall time: 49min 31s\n",
        "```\n",
        "\n",
        "```\n",
        "I0818 17:46:50.941742 140184802654080 run_pretraining.py:483] ***** Eval results *****\n",
        "I0818 17:46:50.941880 140184802654080 run_pretraining.py:485]   global_step = 50000\n",
        "I0818 17:46:50.942254 140184802654080 run_pretraining.py:485]   loss = 0.3655657\n",
        "I0818 17:46:50.942408 140184802654080 run_pretraining.py:485]   masked_lm_accuracy = 0.9144256\n",
        "I0818 17:46:50.942533 140184802654080 run_pretraining.py:485]   masked_lm_loss = 0.33980185\n",
        "I0818 17:46:50.942634 140184802654080 run_pretraining.py:485]   next_sentence_accuracy = 0.99625\n",
        "I0818 17:46:50.942719 140184802654080 run_pretraining.py:485]   next_sentence_loss = 0.013906714\n",
        "CPU times: user 48.4 s, sys: 7.54 s, total: 56 s\n",
        "Wall time: 2h 22min 54s\n",
        "```\n",
        "\n",
        "```\n",
        "I0819 06:43:39.739752 139906677770112 run_pretraining.py:483] ***** Eval results *****\n",
        "I0819 06:43:39.739871 139906677770112 run_pretraining.py:485]   global_step = 100000\n",
        "I0819 06:43:39.740208 139906677770112 run_pretraining.py:485]   loss = 0.2965531\n",
        "I0819 06:43:39.740323 139906677770112 run_pretraining.py:485]   masked_lm_accuracy = 0.9267595\n",
        "I0819 06:43:39.740409 139906677770112 run_pretraining.py:485]   masked_lm_loss = 0.27952158\n",
        "I0819 06:43:39.740486 139906677770112 run_pretraining.py:485]   next_sentence_accuracy = 0.99875\n",
        "I0819 06:43:39.740583 139906677770112 run_pretraining.py:485]   next_sentence_loss = 0.002464915\n",
        "CPU times: user 1min 16s, sys: 11.4 s, total: 1min 27s\n",
        "Wall time: 3h 55min 46s\n",
        "```\n",
        "\n",
        "```\n",
        "I0819 16:27:09.458713 139819099187072 run_pretraining.py:483] ***** Eval results *****\n",
        "I0819 16:27:09.458858 139819099187072 run_pretraining.py:485]   global_step = 200000\n",
        "I0819 16:27:09.459412 139819099187072 run_pretraining.py:485]   loss = 0.25941798\n",
        "I0819 16:27:09.459626 139819099187072 run_pretraining.py:485]   masked_lm_accuracy = 0.93457943\n",
        "I0819 16:27:09.459730 139819099187072 run_pretraining.py:485]   masked_lm_loss = 0.23920113\n",
        "I0819 16:27:09.459816 139819099187072 run_pretraining.py:485]   next_sentence_accuracy = 0.99875\n",
        "I0819 16:27:09.459905 139819099187072 run_pretraining.py:485]   next_sentence_loss = 0.0025768017\n",
        "CPU times: user 2min 42s, sys: 21.3 s, total: 3min 3s\n",
        "Wall time: 7h 50min 29s\n",
        "```\n",
        "\n",
        "```\n",
        "I0820 10:55:42.340659 139671258257280 run_pretraining.py:483] ***** Eval results *****\n",
        "I0820 10:55:42.340777 139671258257280 run_pretraining.py:485]   global_step = 300000\n",
        "I0820 10:55:42.341297 139671258257280 run_pretraining.py:485]   loss = 0.19169405\n",
        "I0820 10:55:42.341431 139671258257280 run_pretraining.py:485]   masked_lm_accuracy = 0.95320743\n",
        "I0820 10:55:42.341532 139671258257280 run_pretraining.py:485]   masked_lm_loss = 0.16689053\n",
        "I0820 10:55:42.341613 139671258257280 run_pretraining.py:485]   next_sentence_accuracy = 1.0\n",
        "I0820 10:55:42.341696 139671258257280 run_pretraining.py:485]   next_sentence_loss = 4.6706875e-05\n",
        "CPU times: user 1min 38s, sys: 15.4 s, total: 1min 53s\n",
        "Wall time: 5h 20min 8s\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp9YOWPzk6vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}