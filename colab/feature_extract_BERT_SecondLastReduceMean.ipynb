{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature-extract-BERT-SecondLastReduceMean.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoheikikuta/US-patent-analysis/blob/master/colab/feature_extract_BERT_SecondLastReduceMean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrjAnqmEptPR",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction from BERT model\n",
        "\n",
        "Use the second last mean of the features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyqYP3mJYhIX",
        "colab_type": "code",
        "outputId": "ca54c5e3-80f5-4daf-86cf-20fb3325e302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0807 13:09:10.675693 140446435125120 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJGPX8YnXIhb",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation\n",
        "\n",
        "Since the input of the BERT model is token-ids corresponding to tokens using the BERT tokenization, use the prepared tokenization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXoWDsdBXF9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = \"./\"\n",
        "\n",
        "class ModelInfo:\n",
        "  gcs_model_path = \"gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/\"\n",
        "  model_path = DATA_DIR + \"uncased_L-12_H-768_A-12/\"\n",
        "  feature_dim = 768\n",
        "  gcs_save_path = \"gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-extracted-feature/BERT-2ndlastmean/\"\n",
        "  \n",
        "  ### For Large model.\n",
        "#   gcs_model_path = \"gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-24_H-1024_A-16/\"\n",
        "#   model_path = DATA_DIR + \"uncased_L-24_H-1024_A-16/\"\n",
        "#   feature_dim = 1024\n",
        "#   gcs_save_path = \"gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-extracted-feature/BERT-Large-2ndlastmean/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR8af_4iYEn7",
        "colab_type": "code",
        "outputId": "b2219c53-a6c6-433c-ca19-39d9a99bacc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "!gsutil cp -r {ModelInfo.gcs_model_path} {DATA_DIR}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/bert_config.json...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/bert_model.ckpt.index...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/bert_model.ckpt.meta...\n",
            "/ [4 files][420.9 MiB/420.9 MiB]   22.0 MiB/s                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/checkpoint...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/vocab.txt...\n",
            "- [6 files][421.1 MiB/421.1 MiB]   16.5 MiB/s                                   \n",
            "Operation completed over 6 objects/421.1 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyJRzKyxXRwG",
        "colab_type": "code",
        "outputId": "8e09cd98-31df-41ea-94c2-10a4a1659dd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "!gsutil cp gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/grants_for_3000+3000.df.gz {DATA_DIR}\n",
        "!gsutil cp gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/testset_app_3000.df.gz {DATA_DIR}\n",
        "!gsutil cp gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/training_app_3000.df.gz {DATA_DIR}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/grants_for_3000+3000.df.gz...\n",
            "/ [1 files][129.4 MiB/129.4 MiB]                                                \n",
            "Operation completed over 1 objects/129.4 MiB.                                    \n",
            "Copying gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/testset_app_3000.df.gz...\n",
            "| [1 files][ 45.5 MiB/ 45.5 MiB]                                                \n",
            "Operation completed over 1 objects/45.5 MiB.                                     \n",
            "Copying gs://yohei-kikuta/mlstudy-phys/patent-analysis/3000-xml/training_app_3000.df.gz...\n",
            "/ [1 files][ 45.0 MiB/ 45.0 MiB]                                                \n",
            "Operation completed over 1 objects/45.0 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOsxlbD7XsPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gzip\n",
        "import pickle\n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyu2rc5gXPV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grants = pd.read_pickle(f\"{DATA_DIR}grants_for_3000+3000.df.gz\")\n",
        "test_app = pd.read_pickle(f\"{DATA_DIR}testset_app_3000.df.gz\")\n",
        "train_app = pd.read_pickle(f\"{DATA_DIR}training_app_3000.df.gz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUeFwt1UXVOa",
        "colab_type": "code",
        "outputId": "44322d3d-9768-4324-ff4d-b45a486c9feb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "train_app.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>app_id</th>\n",
              "      <th>xml</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12130785</td>\n",
              "      <td>&lt;us-patent-application lang=\"EN\" dtd-version=\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12652424</td>\n",
              "      <td>&lt;us-patent-application lang=\"EN\" dtd-version=\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12214532</td>\n",
              "      <td>&lt;us-patent-application lang=\"EN\" dtd-version=\"...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     app_id                                                xml\n",
              "0  12130785  <us-patent-application lang=\"EN\" dtd-version=\"...\n",
              "1  12652424  <us-patent-application lang=\"EN\" dtd-version=\"...\n",
              "2  12214532  <us-patent-application lang=\"EN\" dtd-version=\"..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfN0wdBGXXEU",
        "colab_type": "code",
        "outputId": "c459de1f-9e59-4be4-8c39-8c9f22aa0360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!git clone https://github.com/google-research/bert.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 333, done.\u001b[K\n",
            "remote: Total 333 (delta 0), reused 0 (delta 0), pack-reused 333\u001b[K\n",
            "Receiving objects: 100% (333/333), 279.30 KiB | 3.77 MiB/s, done.\n",
            "Resolving deltas: 100% (183/183), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpVJo-GuXsrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"./bert\")\n",
        "\n",
        "import tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCI3LpKDXsw_",
        "colab_type": "code",
        "outputId": "c1321b52-379e-462e-87ad-e04b100347c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "tokenizer = tokenization.FullTokenizer(\n",
        "    vocab_file=f\"{ModelInfo.model_path}vocab.txt\", do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0807 13:10:12.149398 140446435125120 deprecation_wrapper.py:119] From ./bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ea0njf9Xs3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def claim_to_ids(claim):\n",
        "  return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(claim))\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "CLAIM_PAT = re.compile(r'<claims[^>]*>(.*)</claims>',re.MULTILINE|re.DOTALL)\n",
        "TAG_PAT = re.compile(r\"<.*?>\")\n",
        "LB_PAT = re.compile(r'[\\t\\n\\r\\f\\v][\" \"]*')\n",
        "CANCELED_PAT = re.compile(r'[0-9]+.*\\. \\(canceled\\)[\" \"]')\n",
        "NUM_PAT = re.compile(r'[\" \"]?[0-9]+[\" \"]?\\.[\" \"]?')\n",
        "\n",
        "def whole_xml_to_claim_xml(whole):\n",
        "    mat = CLAIM_PAT.search(whole)\n",
        "    return mat.group(1)\n",
        "def whole_xml_to_claim(whole):\n",
        "    return TAG_PAT.sub(' ', whole_xml_to_claim_xml(whole))\n",
        "\n",
        "def remove_linebreak_from_claim(claim):\n",
        "    return LB_PAT.sub('', claim)\n",
        "\n",
        "def remove_canceled_claim(claim):\n",
        "    return CANCELED_PAT.sub('', claim)\n",
        "  \n",
        "def remove_claim_numbers(claim):\n",
        "    return NUM_PAT.sub('', claim)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uBXKcFaZfU6",
        "colab_type": "code",
        "outputId": "2493bb2a-3267-4ede-b8db-f6a0419b468d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "train_ids = [claim_to_ids(claim) for claim in train_app[\"xml\"].map(whole_xml_to_claim).map(remove_canceled_claim).map(remove_claim_numbers).map(remove_linebreak_from_claim)]\n",
        "test_ids = [claim_to_ids(claim) for claim in test_app[\"xml\"].map(whole_xml_to_claim).map(remove_canceled_claim).map(remove_claim_numbers).map(remove_linebreak_from_claim)]\n",
        "grants_ids = [claim_to_ids(claim) for claim in grants[\"xml\"].map(whole_xml_to_claim).map(remove_canceled_claim).map(remove_claim_numbers).map(remove_linebreak_from_claim)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 35s, sys: 414 ms, total: 5min 35s\n",
            "Wall time: 5min 35s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIwGJjU_4vUe",
        "colab_type": "code",
        "outputId": "c0560043-9445-4b30-bcac-291373ce843a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "list(map(len, train_ids))[:10], list(map(len, test_ids))[:10], list(map(len, grants_ids))[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([774, 1065, 1698, 486, 1863, 724, 711, 566, 1724, 1469],\n",
              " [3296, 3724, 2410, 295, 286, 216, 832, 407, 2111, 1121],\n",
              " [1491, 671, 417, 1441, 4625, 2778, 322, 643, 1016, 2518])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gie_utNz4yV9",
        "colab_type": "code",
        "outputId": "870aee4a-2145-4185-ba04-ce38ade280b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "train_ids[0][:10], train_ids[1500][:10], train_ids[-1][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1037, 2291, 2005, 2367, 15370, 5005, 2013, 2019, 12098, 25032],\n",
              " [1037, 6276, 6994, 2383, 1037, 16305, 2364, 2303, 1998, 1037],\n",
              " [1037, 6381, 6121, 4653, 14709, 2008, 7711, 6381, 14438, 2007])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKrSqn8E40-o",
        "colab_type": "code",
        "outputId": "3ccd693a-a6a3-456a-936e-930be0fc3489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "test_ids[0][:10], test_ids[1500][:10], test_ids[-1][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1037, 4118, 2005, 5464, 2019, 9178, 2114, 1037, 2177, 1997],\n",
              " [1037, 4118, 1997, 4488, 2019, 3169, 1999, 1037, 4942, 17310],\n",
              " [1037, 17880, 1011, 29014, 3252, 9605, 1024, 1037, 23604, 19395])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKDlW56B429X",
        "colab_type": "code",
        "outputId": "01913557-3feb-4932-f9b2-383e683c668f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "grants_ids[0][:10], grants_ids[1500][:10], grants_ids[-1][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1037, 4118, 2005, 12515, 2019, 4358, 10146, 1997, 1037, 8331],\n",
              " [2019, 9413, 7446, 22026, 18921, 6218, 4057, 3085, 2000, 1037],\n",
              " [1037, 4118, 9605, 1024, 4909, 1037, 5227, 2013, 1037, 7396])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHxlDEbGamCa",
        "colab_type": "text"
      },
      "source": [
        "## Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bUs4a_Yaa4h",
        "colab_type": "code",
        "outputId": "986d04a7-2a43-4829-dc7b-a44655bc5c6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtDg-xLaabAL",
        "colab_type": "code",
        "outputId": "6ef0636c-9e2c-4665-d4f6-d97001883366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.127.203.82:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 18155664102575052123),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 181401334104015189),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 5097573642739295921),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 5477618557185349819),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 8972939774992622740),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 6818830325481115855),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 16118514186278571439),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 5840110353621396503),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 656313912270314510),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16055682304714498046),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 17062586692573044364)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4ntLUZIa4ij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLS_ID = tokenizer.vocab[\"[CLS]\"]\n",
        "SEP_ID = tokenizer.vocab[\"[SEP]\"]\n",
        "\n",
        "max_seq_length = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v0mLdEbEE5N",
        "colab_type": "code",
        "outputId": "e11421f1-68a3-4c0f-c77c-2843c033b556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "CLS_ID, SEP_ID"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101, 102)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alImZubha4f4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_single_sentence(ids_a_input, uniqueue_id):\n",
        "  ids_a = ids_a_input\n",
        "  # Account for [CLS] and [SEP] with \"- 2\"\n",
        "  if len(ids_a_input) > max_seq_length - 2:\n",
        "    ids_a = list(ids_a_input)[0:(max_seq_length - 2)]  \n",
        "      \n",
        "\n",
        "  # The convention in BERT is:\n",
        "  # (b) For single sequences:\n",
        "  #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "  #  type_ids: 0     0   0   0  0     0 0\n",
        "  #\n",
        "  # Where \"type_ids\" are used to indicate whether this is the first\n",
        "  # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "  # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "  # embedding vector (and position vector). This is not *strictly* necessary\n",
        "  # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "  # it easier for the model to learn the concept of sequences.\n",
        "  #\n",
        "  # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "  # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "  # the entire model is fine-tuned.\n",
        "  input_ids = []\n",
        "  segment_ids = []\n",
        "  input_ids.append(CLS_ID)\n",
        "  segment_ids.append(0)\n",
        "  for token in ids_a:\n",
        "    input_ids.append(token)\n",
        "    segment_ids.append(0)\n",
        "  input_ids.append(SEP_ID)\n",
        "  segment_ids.append(0)\n",
        "\n",
        "  # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "  # tokens are attended to.\n",
        "  input_mask = [1] * len(input_ids)\n",
        "\n",
        "  # Zero-pad up to the sequence length.\n",
        "  while len(input_ids) < max_seq_length:\n",
        "    input_ids.append(0)\n",
        "    input_mask.append(0)\n",
        "    segment_ids.append(0)\n",
        "\n",
        "  assert len(input_ids) == max_seq_length\n",
        "  assert len(input_mask) == max_seq_length\n",
        "  assert len(segment_ids) == max_seq_length\n",
        "\n",
        "  return (input_ids, input_mask, segment_ids, uniqueue_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMTgNx3VLaFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check = convert_single_sentence(train_ids[0], 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXaoVvOHLtO0",
        "colab_type": "code",
        "outputId": "fdbdedb5-a7f0-4b31-8892-d574ef19ba95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "check[0][:5], check[1][:5], check[2][:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([101, 1037, 2291, 2005, 2367], [1, 1, 1, 1, 1], [0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q15XiJ1gbbRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_TRAINING=10000\n",
        "BASE_TEST = 20000\n",
        "BASE_GRANTS = 30000\n",
        "\n",
        "\n",
        "# unique_id, tokens, input_ids, input_mask, input_type_ids\n",
        "def feature_tuplist_to_feature_dict(ftups):\n",
        "    dic = {}\n",
        "    dic['input_ids'] = [tup[0] for tup in ftups]\n",
        "    dic[\"input_mask\"] = [tup[1] for tup in ftups]\n",
        "    dic[\"input_type_ids\"] = [tup[2] for tup in ftups]\n",
        "    dic['unique_ids'] = [tup[3] for tup in ftups]\n",
        "    return dic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-hoDDPjMWgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check = feature_tuplist_to_feature_dict([check])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aZqj4MWMfOQ",
        "colab_type": "code",
        "outputId": "45059d6e-ae29-45d7-c962-f372b8338871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "check['input_ids'][0][:5], check['input_mask'][0][:5], check['input_type_ids'][0][:5], check['unique_ids'][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([101, 1037, 2291, 2005, 2367], [1, 1, 1, 1, 1], [0, 0, 0, 0, 0], 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tCJQHpzbd5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import modeling\n",
        "from extract_features import model_fn_builder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv0e5mOobd2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_config = modeling.BertConfig.from_json_file(f\"{ModelInfo.model_path}bert_config.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCtFTqV5bbOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FLAGS(object):\n",
        "    '''Parameters.'''\n",
        "    def __init__(self):\n",
        "        self.vocab_file = f\"{ModelInfo.model_path}vocab.txt\"\n",
        "        self.use_tpu = True\n",
        "        self.output_dir = \"./\"\n",
        "        self.init_checkpoint = f\"{ModelInfo.gcs_model_path}bert_model.ckpt\"\n",
        "#         self.init_checkpoint = \"gs://mlstudy-phys/mlstudy-phys/bert/model/patent_1000/model.ckpt-1637\"  # fine-tuned model\n",
        "        self.predict_batch_size = 16\n",
        "        # TPU related\n",
        "        self.num_tpu_cores = 8\n",
        "        self.tpu_name = TPU_ADDRESS\n",
        "        \n",
        "        # following parameters are not used anymore. (because we create feature by hand)\n",
        "        self.do_lower_case = True\n",
        "        self.max_seq_length = 512\n",
        "        \n",
        "        # The following parameters are not used in predictions.\n",
        "        # Just use to create RunConfig.\n",
        "        self.master = None\n",
        "        self.save_checkpoints_steps = 1\n",
        "        self.learning_rate = 0\n",
        "        self.num_warmup_steps = 0\n",
        "        self.num_train_steps = 0\n",
        "        # TPU related. Some of these value have positive int not to make TPUEstimator angry (even though these are not used...).\n",
        "        self.eval_batch_size = 32\n",
        "        self.train_batch_size = 32 \n",
        "        self.iterations_per_loop = 1000\n",
        "\n",
        "        \n",
        "FLAGS = FLAGS()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-j7un74bbLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu=FLAGS.tpu_name)\n",
        "\n",
        "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
        "\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    master=FLAGS.master,\n",
        "    model_dir=FLAGS.output_dir,\n",
        "    save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=FLAGS.iterations_per_loop,\n",
        "        num_shards=FLAGS.num_tpu_cores,\n",
        "        per_host_input_for_training=is_per_host))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP_Xbd_Zaa8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "    bert_config=bert_config,\n",
        "    init_checkpoint=FLAGS.init_checkpoint,\n",
        "    use_tpu=FLAGS.use_tpu,\n",
        "    layer_indexes=[-2], # Use the second last hidden layer\n",
        "    use_one_hot_embeddings=FLAGS.use_tpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0vejxsecH6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/kyzhouhzau/BERT-NER/issues/19\n",
        "\n",
        "def model_fn_wrapper(features, labels, mode, params):\n",
        "  tspec = model_fn(features, labels, mode, params)\n",
        "  # We use the second last layer!\n",
        "  pred_dict = {'predictions': tspec.predictions['layer_output_0']}\n",
        "  return tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=tspec.mode, predictions=pred_dict, scaffold_fn=tspec.scaffold_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuUFVY4Ycb4E",
        "colab_type": "code",
        "outputId": "8cdb1a46-e083-416a-d294-31ef0732ee50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=FLAGS.use_tpu,\n",
        "    # model_fn=model_fn,\n",
        "    model_fn=model_fn_wrapper,\n",
        "    config=run_config,\n",
        "    train_batch_size=FLAGS.train_batch_size,\n",
        "    eval_batch_size=FLAGS.eval_batch_size,\n",
        "    predict_batch_size=FLAGS.predict_batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0807 13:15:51.379627 140446435125120 estimator.py:1984] Estimator's model_fn (<function model_fn_wrapper at 0x7fbbf47dad08>) includes params argument, but params are not passed to Estimator.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFXuCE44cb_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRbIySKgcb1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKIX0oaxdlQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ids_to_input_fdict(ids, base_id):\n",
        "  return feature_tuplist_to_feature_dict([convert_single_sentence(one_app, base_id+idx) for idx, one_app in enumerate(ids)])\n",
        "\n",
        "def fdict_to_features(fdict):\n",
        "\n",
        "  def _batch_input_function(params):\n",
        "    test_ds = tf.data.Dataset.from_tensor_slices(fdict)    \n",
        "    return test_ds.batch(params['batch_size'])\n",
        "\n",
        "  feature_results =  np.empty((0, ModelInfo.feature_dim), float)\n",
        "  print(datetime.datetime.today())\n",
        "  result = estimator.predict(_batch_input_function, yield_single_examples=True)\n",
        "  \n",
        "  for idx, one in enumerate(result):\n",
        "    # reduce mean.\n",
        "    mask = fdict[\"input_mask\"][idx]\n",
        "    validlen = sum(mask)\n",
        "    features = one['predictions'].reshape(512, ModelInfo.feature_dim).sum(axis=0) / validlen\n",
        "    \n",
        "    feature_results = np.append(feature_results, features.reshape(1, ModelInfo.feature_dim), axis=0)  \n",
        "  print(datetime.datetime.today())\n",
        "  return feature_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrkrOi--dmCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GS_BASE = ModelInfo.gcs_save_path\n",
        "\n",
        "TRAIN_FEATURE_FNAME = \"bert_2ndlastmean_feature_train_app_3000.pkl.gz\"\n",
        "TEST_FEATURE_FNAME = \"bert_2ndlastmean_feature_test_app_3000.pkl.gz\"\n",
        "GRANTS_FEATURE_FNAME = \"bert_2ndlastmean_feature_grants_3000_3000.pkl.gz\"\n",
        "\n",
        "# TRAIN_FEATURE_FNAME = \"bert_large_2ndlastmean_feature_train_app_3000.pkl.gz\"\n",
        "# TEST_FEATURE_FNAME = \"bert_large_2ndlastmean_feature_test_app_3000.pkl.gz\"\n",
        "# GRANTS_FEATURE_FNAME = \"bert_large_2ndlastmean_feature_grants_3000_3000.pkl.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw_PT0FrlMCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dump_and_send(fname, obj):\n",
        "  with gzip.open(fname, 'w') as f:\n",
        "     pickle.dump(obj, f)\n",
        "  !gsutil cp {fname} {GS_BASE}{fname}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPUKyRfFilAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSrtl5R3dUX-",
        "colab_type": "code",
        "outputId": "64a0039e-723a-4098-8aa5-c152a7aa71ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_app_input_fdict = ids_to_input_fdict(train_ids, BASE_TRAINING)\n",
        "train_features = fdict_to_features(train_app_input_fdict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-07 13:15:52.440129\n",
            "2019-08-07 13:17:12.904742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak4Dl6j67CWe",
        "colab_type": "code",
        "outputId": "6086b8ca-97d8-4727-f7d7-5a33aa21a4ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_features[0, 0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.61115211,  0.09057721,  0.14272423, -0.23332408,  0.42033839,\n",
              "        0.1024638 ,  0.15721108, -0.2079207 ,  0.28475305,  0.24445903])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8GQ8XpLdUUj",
        "colab_type": "code",
        "outputId": "0d0d0a97-b0f6-4bb3-a645-4bde22e00e3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_features.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt0GIVJ7cH3t",
        "colab_type": "code",
        "outputId": "9624af4e-574e-4b60-a8db-c0e43278af66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "dump_and_send(TRAIN_FEATURE_FNAME, train_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://bert_2ndlastmean_feature_train_app_3000.pkl.gz [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/9.4 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq9aghOzeZyj",
        "colab_type": "code",
        "outputId": "c7d989cb-3dc3-445f-845a-1b325a32eb7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_app_input_fdict = ids_to_input_fdict(test_ids, BASE_TEST)\n",
        "test_features = fdict_to_features(test_app_input_fdict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-07 13:17:43.098740\n",
            "2019-08-07 13:18:45.484968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgG1P3kteZ75",
        "colab_type": "code",
        "outputId": "5dfc5685-04d1-45cd-d31e-1e583d30a759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_features.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzqH9iFJeZ5C",
        "colab_type": "code",
        "outputId": "b1bd1312-5e32-43e0-eee3-14ac786e8a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "dump_and_send(TEST_FEATURE_FNAME, test_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://bert_2ndlastmean_feature_test_app_3000.pkl.gz [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/9.4 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK258VpQl5oe",
        "colab_type": "code",
        "outputId": "d9129554-bba9-41be-f68b-7156735f8c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "grants_input_fdict = ids_to_input_fdict(grants_ids, BASE_GRANTS)\n",
        "grants_features = fdict_to_features(grants_input_fdict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-07 13:19:16.868098\n",
            "2019-08-07 13:21:42.594636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVhGAcCll5jg",
        "colab_type": "code",
        "outputId": "9e2f80e1-9686-45fc-a472-159f964b4754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "grants_features.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6440, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBHIp38omK28",
        "colab_type": "code",
        "outputId": "3f8a5274-aef5-4149-823e-cf092c69bf6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "dump_and_send(GRANTS_FEATURE_FNAME, grants_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://bert_2ndlastmean_feature_grants_3000_3000.pkl.gz [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/20.1 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgfQ2J7qmKym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEeXmmBYmQwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ4Y26eOmQti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2XDywfmcH1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv1YL3tlemB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Gl2k_0NNvv",
        "colab_type": "text"
      },
      "source": [
        "# Trial and Errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AryOboPYNPaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ids_to_input_fdict(ids, base_id):\n",
        "  return feature_tuplist_to_feature_dict([convert_single_sentence(one_app, base_id+idx) for idx, one_app in enumerate(ids)])\n",
        "\n",
        "def fdict_to_features(fdict):\n",
        "\n",
        "  def _batch_input_function(params):\n",
        "    test_ds = tf.data.Dataset.from_tensor_slices(fdict)    \n",
        "    return test_ds.batch(params['batch_size'])\n",
        "\n",
        "  feature_results =  np.empty((0, ModelInfo.feature_dim), float)\n",
        "  print(datetime.datetime.today())\n",
        "  result = estimator.predict(_batch_input_function, yield_single_examples=True)\n",
        "  return result\n",
        "  \n",
        "#   for idx, one in enumerate(result):\n",
        "#     # reduce mean.\n",
        "#     mask = fdict[\"input_mask\"][idx]\n",
        "#     validlen = sum(mask)\n",
        "#     features = one['predictions'].reshape(512, ModelInfo.feature_dim).sum(axis=0) / validlen\n",
        "    \n",
        "#     feature_results = np.append(feature_results, features.reshape(1, ModelInfo.feature_dim), axis=0)  \n",
        "#   print(datetime.datetime.today())\n",
        "#   return feature_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF_oBPquNQW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check_train_app_input_fdict = ids_to_input_fdict(train_ids[:100], BASE_TRAINING)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc65ngiANdQt",
        "colab_type": "code",
        "outputId": "97264e5f-c90f-4719-b0be-e5b9f8d1f4ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "check_train_app_input_fdict['input_ids'][0][:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 1037, 2291, 2005, 2367]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6-coNcyNiyG",
        "colab_type": "code",
        "outputId": "0265baae-8525-4c75-e542-3ae7af5fea9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result = fdict_to_features(check_train_app_input_fdict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-07 04:13:08.340518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQs2hSdQNvPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one = next(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4ZRL7fUN-fQ",
        "colab_type": "code",
        "outputId": "bc18ae7d-a099-4a95-f486-8d9884825dee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "one['predictions'].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km83iVDkOFja",
        "colab_type": "code",
        "outputId": "c1d50b45-28ef-4948-86c4-0d6778759f50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "one['predictions'][0][:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.399356  , -0.86181027, -0.35524815,  0.18730514,  0.3189999 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb5O2-hHPnEJ",
        "colab_type": "text"
      },
      "source": [
        "EXPECTED: \n",
        "\n",
        "array([-0.14263938, -0.6473565 , -0.25649723,  0.19866335,  0.58390003],\n",
        "      dtype=float32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDZ-7sa9Ou2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}